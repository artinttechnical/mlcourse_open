{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "<center> Автор материала: Павел Нестеров (@mephistopheies).\n",
    "\n",
    "Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "sklearn 0.19.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.13.0-37-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 14ed2fef3be0947c413288f2fab224710e26f1f0\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ios', 'android', 'c++', 'jquery', 'php', 'python', 'html', 'java', 'javascript', 'c#'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\textbf{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} = \\sigma_k\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\textbf{x}, y}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\textbf{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\textbf{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\textbf{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\textbf{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font> В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += -y * np.log(np.max([tolerance, sigma])) if y == 1 else \\\n",
    "                                  -(1 - y) * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd62b744479465bab9bd76e192b1574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5sAAAKoCAYAAAD58uunAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl4VOXh/v97MpOVJIQlIewSdsKmEhYRKFbQgjG21K0VFbfWLqnKx34pdPfTn8tHql2sS9UW64Zbi7jUBRUUAZFdQBAUISwhLAlJyDJJ5vfHJJMZMslkmZlnlvfrunr1nDNnTu4LWeae55znsTgcDocAAAAAAPCjGNMBAAAAAACRh7IJAAAAAPA7yiYAAAAAwO8omwAAAAAAv6NsAgAAAAD8jrIJAAAAAPA7WyAvXlRUGsjLAwAAAAAMSk9PafY1RjYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNAAAAAIDfUTYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNAAAAAIDfUTYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNAAAAAIDfUTYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNAAAAAIDfUTYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNAAAAAIDfUTYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNAAAAAIDfUTYBAAAAAH5H2QQAAAAA+B1lEwAAAADgd5RNL2rrHKqprTMdAwAAAADCFmXzDOv3n9TEBz7UpAc/Mh0FAAAAAMIWZdNNncOhH724zXQMAAAAAAh7lE03OwvLPPZzFq/idloAAAAAaIeoLpt7j5Vr6caDuuX5zapp5jlNbqcFAAAAgLazmQ5g0lVLNri2Jz3wocEkAAAAABBZonpkEwAAAAAQGFFdNl+cN87r8X9+/2yP/c8On5IkPb7ma63ccyzguQAAAAAg3EV12Tyra5LX49mZKR77857dLEl69OOv9T/LdgQ8FwAAAACEu6gum5J0x/SBSkuMbXJ85tB0j32Hw+HarrTXBjwXAAAAAISzqC+bV5/TWz//5qAmx2//RpYSYxt/edbvL3Ztl1VTNgEAAACgJVFfNiVpdK/UJse6J8drVf75rv3739vr2v7rh18FJRcAAAAAhCvKpqQeKfF6cd449UiJ1/Kbx3s956sTp13br28vDFY0AAAAAAhLlM16Z3VN0mu3TFBmaoLH8RFnTBYEAAAAAPCNsunDH2YPMx0BAAAAAMIOZdOHnmeMdJ7d2/l8Z02dw9vpAAAAAABJFof7mh5+VlRUGqhLB1XxabsSYmOUEGvVba98ptVfnZAkrZ8/1XAyAAAAADAnPb35xw5tQcwRttKSGtfh7BRnNZgEAAAAAMIDt9G20f+6PcMZwEFhAAAAAAhrlM02slgsru2DJZUGkwAAAABA6KJstsP0wd0lSX9f87XhJAAAAAAQmiib7fCt4RmSpDd2HDWcBAAAAABCE2WzHTJS4k1HAAAAAICQRtlsh7TExkl8mSQIAAAAAJqibLZD786Jru339xw3mAQAAAAAQhNls4PW7TtpOgIAAAAAhBzKZjtdP76vJOmVrYcNJwEAAACA0EPZbKcfnNffdAQAAAAACFmUzXayWRt/6XIWr9KJ09UG0wAAAABAaKFs+sltr3xmOgIAAAAAhAzKpp/065Lo+yQAAAAAiBKUzQ7omhTr2k6KsxpMAgAAAAChhbLZAZmpCa7tf289YjAJAAAAAIQWymYHXDC4u+kIAAAAABCSKJsd8P1ze7u2R/ZMMZgEAAAAAEILZbMDbNYYvX3rRE0e0FXlVbWm4wAAAABAyKBsdlCXpDh16xSr8uoa01EAAAAAIGRQNv0gOd6mo2XVqqlzmI4CAAAAACGBsukHFXbnLbSTHvjQcBIAAAAACA2UTT+osNe5tuc9u8lgEgAAAAAIDZRNP/vscKnpCAAAAABgnM+yefjwYc2dO1ezZs3S7NmztWTJEtdr//rXv3TxxRdr9uzZuu+++wIaNJT165LosX/fij0qq2LCIAAAAADRy+brBKvVqgULFig7O1tlZWWaM2eOJk+erGPHjmnFihV69dVXFRcXp+PHjwcjb0iaN6Gf+ndJ1KLXP5ckvbj5kKwxFs2fPtBwMgAAAAAww+fIZkZGhrKzsyVJycnJysrKUmFhoZ577jndcsstiouLkyR169YtsElDmC3GopnDMjyOvburyFAaAAAAADCvTc9sFhQUaOfOnRozZoz27dunTz/9VJdffrmuueYabd26NVAZw9Kx8mrTEQAAAADAGJ+30TYoLy9Xfn6+Fi5cqOTkZNXW1qqkpEQvvPCCtm3bpttuu00rVqyQxWIJZF4AAAAAQBho1cim3W5Xfn6+cnNzNXPmTElSjx49NGPGDFksFo0ePVoxMTE6efJkQMOGund+NEn35A43HQMAAAAAjPNZNh0OhxYtWqSsrCzNmzfPdfzCCy/UunXrJElfffWV7Ha7unTpErikYSAtMVbfHJJuOgYAAAAAGOfzNtoNGzZo2bJlGjJkiPLy8iRJd9xxh+bMmaOFCxfqkksuUWxsrO655x5uoT3Dl8fLldWtk+kYAAAAABB0FofD4QjUxYuKSgN16ZCWs3iVJOl33xqqWSN6GE4DAAAAAIGRnp7S7Gttmo0WbbOxoMR0BAAAAAAwgrIZAP/43lhJ0vh+aYaTAAAAAIAZlM0A6JESL0la9PrnhpMAAAAAgBmUzQDokhRnOgIAAAAAGEXZDABbTOOsvBX2Wu04Ep0TJQEAAACIXpTNAPv1G5/rumc2qayqxnQUAAAAAAgaymaAbaqfkbaorNpwEgAAAAAIHspmgEwd2E2SVF5dK0m64p+fmowDAAAAAEFF2QyQ1ASbJKmmzmE4CQAAAAAEH2UzQF7bXuixH2/jlxoAAABA9KABBUhudg+P/aqaOkNJAAAAACD4KJsBsuDCwaYjAAAAAIAxlM0AifNy26zDwfObAAAAAKIDZTMIRvdKlST9e+thw0kAAAAAIDgom0Gw9dApSdK/tx4xnAQAAAAAgoOyGUBXjO2lEZkprv3Pj5YZTAMAAAAAwWMzHSCS3fnNQZKk0soaXfDQx8qfOsBwIgAAAAAIDkY2g6Bhjc2aOiYIAgAAABAdKJtBEGu1SJKqWWsTAAAAQJSgbAaBxWJRrNWi6lpGNgEAAABEB8pmkMRZY2SvZWQTAAAAQHSgbAZJrDVGr+8o1MdfnTAdBQAAAAACjrIZJMUVdp2qrNHPXvnMdBQAAAAACDjKJgAAAADA7yibBry2/YhW7C4yHQMAAAAAAsZmOkA0+t1/d0uS/vm9eGX3TDWcBgAAAAD8j5HNIElPjmtyrMLO7LQAAAAAIhNlM0j+c+N4PXXN2R7H4m388gMAAACITLSdIImzxWh4jxSPYxX2WkNpAAAAACCwKJsGUTYBAAAARCrKpkGnKZsAAAAAIhRlM8henDdOP5uWJUn69Ru7DKcBAAAAgMCgbAbZWV2TdNmoTNf+b9783GAaAAAAAAgMyqYBCbFW1/YbO44aTAIAAAAAgUHZNMAWY/HYr3M4DCUBAAAAgMCgbBpy1Tm9XdtFZdUGkwAAAACA/1E2DZk/faBru7y6xmASAAAAAPA/ymYIWLB8p+kIAAAAAOBXlE2D/jJnpCTpq+OnDScBAAAAAP+ibBo0pndn0xEAAAAAICAomwYl2PjlBwAAABCZaDsGWSyNS6DU1rH8CQAAAIDIQdk07Afn9ZckbT10SpsKSgynAQAAAAD/sJkOEO16piZIkm5ZukWStH7+VJNxAAAAAMAvGNk0LDmevg8AAAAg8lA2DTt+utpjv6qmzlASAAAAAPAfyqZhIzNTPPZPnlE+AQAAACAcUTYNG5KRrDirRbYY58y0uX//RBsLig2nAgAAAICOsTgcjoCtuVFUVBqoS0ecLQdLdNPzW1z7TBQEAAAAINSlp6c0+xojmyGihnU2AQAAAEQQymaIyD7j2U17LRMFAQAAAAhflM0QkRBr9dhfsfuYoSQAAAAA0HGUzRCS5FY4i8qqDCYBAAAAgI6hbIaQlfmT9dy150qSunWKM5wGAAAAANqPshli0pJiJUm/eXOX4SQAAAAA0H6UzRDTtb5sAgAAAEA4o2yGmBiLxbVdw4y0AAAAAMIUZTOEVdZQNgEAAACEJ8pmCFpw4SBJlE0AAAAA4YuyGYISbM4lUCrttT7P/euHX+mR1fsCnAgAAAAA2oayGYLibc7/LK0Z2VzyyQE9sXa/a39PUbm+PF4esGwAAAAA0Bo20wHQVEPZPF5erUHdOzV7nsPhcG2v23dSBSUVuufdPZKktbdPkTXG0txbAQAAACCgGNkMQbV1zhLpqyq+s6vItf2Tl7e5iqYkXbXkU48yCgAAAADBRNkMQT1S4yVJ+06cbvG8HUfKmn1t34kKLX5/r19zAQAAAEBrUTZDUGyM8z/L/73Xclkc2D2pxdeXbjrkt0wAAAAA0BaUzRDkXiJbuhW24dnOBsN7JOuh745y7XdNivV/OAAAAABoBSYICkEWS+PTmp98XawJZ3Xxet6pyhpJ0h9mD9M5fTqre7Lz9ltbjEU1dQ6dOG0PfFgAAAAA8MLnyObhw4c1d+5czZo1S7Nnz9aSJUskSX/5y180ZcoU5eXlKS8vTytXrgx42Gh0rLza6/FFr+3UvSucEwKd0zfNVTQlac3tU4KSDQAAAACa43Nk02q1asGCBcrOzlZZWZnmzJmjyZMnS5Kuv/563XjjjQEPGY1+ddEQ3fXWbm04UKzZ2T08Xlv+2RG97TYTbby1+e8MjpZWKSMlvtnXAQAAACAQfI5sZmRkKDs7W5KUnJysrKwsFRYWBjxYtEtPjpMkLd/e9Nf692/t9tjvFG9t9jpFzYyMAgAAAEAgtWmCoIKCAu3cuVNjxoyRJD3zzDPKzc3VL37xC5WUlAQkYLTK6Zvm2i6tfzbTm/ypAxRjaboi54yh6ZKkiupa/4cDAAAAAB9aXTbLy8uVn5+vhQsXKjk5WVdffbXeeecdLVu2TBkZGbrnnnsCmTPq2Nxujf3uP9Y3e15tnffZas/p01mSdOuLW/0bDAAAAABaoVVl0263Kz8/X7m5uZo5c6YkqXv37rJarYqJidHll1+ubdu2BTRoNHOfVbbS7jlSea7bCKi7bw7pHtBMAAAAANASn2XT4XBo0aJFysrK0rx581zHjx496tp+9913NXjw4MAkjGK/umhIk2MbDnjerjyqV6rX93ZJigtIJgAAAABoDZ+z0W7YsEHLli3TkCFDlJeXJ0m644479Nprr+nzzz+XJPXu3Vu///3vA5s0Cs0cmq67zpgM6A/vNO4/+O2RrbpOdU2d4mxtejwXAAAAADrEZ9kcN26cdu3a1eT4tGnTAhIIjRJiG2eZzVm8Smtvn6KiMufssku+f7ZGZKa0+P7hPZK1s7BMnx4o1nkDugY0KwAAAAC4Y7grjBw+Venabs3amTsLyyRJi9/fG7BMAAAAAOANZTOMVNrrNCXLOULZvZPvZzLvyR0uSUqO9zmADQAAAAB+RQsJI1c/tUGS1K9LYqvOnz7YOSPtjiOlAcsEAAAAAN4wshni7r5keJNj+09WtOq9MRaLv+MAAAAAQKtQNkPchUPT9eYPJ5qOAQAAAABtQtkMA2mJsR2+Rs7iVbrh2U1+SAMAAAAAvlE2w4AtxvN22CvP7tWu62w7zLObAAAAAIKDshkm3rl1kmv7nL5prX7ftTl9AhEHAAAAAFpE2QwTaUmx+v/qJwsa0yu11e/L7tn6cwEAAADAX1j6JIzMGJquGUPT2/Se7MyUAKUBAAAAgOYxshnhuiZ5Ti5UXl1jKAkAAACAaELZjHCxVs//xNU1dYaSAAAAAIgmlM0oU2GnbAIAAAAIPMpmFFg/f6ryRmVKkq59eqPhNAAAAACiAWUzSpRX1UqSSip5ZhMAAABA4FE2o8QvLxosSfrh5P6GkwAAAACIBpTNKJEUa5Uk1dQ6DCcBAAAAEA0om1HCYrEo3hajKmajBQAAABAElM0oUlVTp399WmA6BgAAAIAoQNkEAAAAAPgdZRMAAAAA4HeUzShydu9USZLDwSRBAAAAAAKLshlFNh08JUkqr641nAQAAABApKNsRpGbJvaTJE3/68cqKqsynAYAAABAJKNsRpHH1+53bT+34aDBJAAAAAAiHWUzirx8Q45ru5bnNgEAAAAEEGUzivTrkujafpaRTQAAAAABRNmMYlsOlpiOAAAAACBCUTaj2E3Pb1FpZY3pGAAAAAAiEGUzyiy/ebzH/h8/2GsoCQAAAIBIRtmMMpmpCR77r20vNJQEAAAAQCSjbAIAAAAA/I6yGYV+dP5Zru1enROaPxEAAAAA2omyGYXmTein9fOnauJZXdQlMdZ0HAAAAAARyGY6AMxZu++k6QgAAAAAIhQjm9AHXxwzHQEAAABAhKFsQne+usN0BAAAAAARhrIZxWaNyHBt19Q5DCYBAAAAEGkom1Fs/vSBru1JD3xoMAkAAACASEPZjGKpCZ4z0dY5GN0EAAAA4B+UzSi3/Obxru2bn99iMAkAAACASELZjHKZqQmu7dPVtQaTAAAAAIgklE1owYWDJEl7jpUbTgIAAAAgUlA2oTljepmOAAAAACDCUDYBAAAAAH5H2YQkKTszxXQEAAAAABGEsglJUla3JEnSwZIKw0kAAAAARALKJiRJy7cXSpLyX/7McBIAAAAAkYCyCUnSxLO6SJLG9Eo1nAQAAABAJKBsQpK0aMZgSY0jnAAAAADQEZRNSJLSEmNNRwAAAAAQQWymAyA0JMRa1SnOqgH1EwUBAAAAQEcwsgmXc/umqaqmznQMAAAAABGAsgmXtESbvigqNx0DAAAAQASgbMJlY0GJJCln8SrDSQAAAACEO8omXAqKK13b24+UGkwCAAAAINxRNuHV0o0HTUcAAAAAEMYom3C5N3e4a3tsn84GkwAAAAAId5RNuFwwJN21HRtjMZgEAAAAQLijbMLDOz+aJEk6XV1rOAkAAACAcEbZhIdOcVZJ0onT1YaTAAAAAAhnlE14iLU6f0scK6dsAgAAAGg/yiaaSLDFuEonAAAAALQHjQJNpCXGqrKmznQMAAAAAGGMsokmjpRW6fXthaZjAAAAAAhjlE0AAAAAgN9RNtGsmjqH6QgAAAAAwpTPsnn48GHNnTtXs2bN0uzZs7VkyRKP15988kkNHTpUJ06cCFhImHHJY+tMRwAAAAAQpmy+TrBarVqwYIGys7NVVlamOXPmaPLkyRo0aJAOHz6s1atXq1evXsHIiiA7zvInAAAAANrJ58hmRkaGsrOzJUnJycnKyspSYaFz8pi7775bd955pywWS2BTIqj+fuUY0xEAAAAAhLk2PbNZUFCgnTt3asyYMXr33XeVkZGhYcOGBSobDBnbp7Nru7qmTh98cUwOB89vAgAAAGg9n7fRNigvL1d+fr4WLlwoq9WqRx99VE8++WQgsyEETP7TR5Kkq8/prTumDzScBgAAAEC4aNXIpt1uV35+vnJzczVz5kzt379fBQUFysvL0wUXXKAjR47oO9/5joqKigKdF4Y8t/Gg6QgAAAAAwojPkU2Hw6FFixYpKytL8+bNkyQNHTpUa9ascZ1zwQUX6KWXXlLXrl0DlxRBNWdMT7285bDpGAAAAADClM+RzQ0bNmjZsmVau3at8vLylJeXp5UrVwYjGwy6eVJ/j/2JZ3UxlAQAAABAOLI4AjjzS1FRaaAujSDIWbzKY3/lTycrKc5qKA0AAACAUJOentLsa22ajRbRZXiPZI/9r46XG0oCAAAAINxQNtGsRTOHeOxf/+xmQ0kAAAAAhBvKJpo1NCNZL80bp+euPdd0FAAAAABhptXrbCI69e+aZDoCAAAAgDDEyCYAAAAAwO8om2iTorIq0xEAAAAAhAHKJtpk1qPrTEcAAAAAEAYomwAAAAAAv6NsolX+c1OO6QgAAAAAwghlE63Su3Oia7vSXmswCQAAAIBwQNlEm03582rTEQAAAACEOMomAAAAAMDvKJtotZR4mySpV+cEw0kAAAAAhDrKJlrtsavGSJIOlVQaTgIAAAAg1FE20WqDundybecsXmUwCQAAAIBQR9kEAAAAAPgdZRNt8uTVY01HAAAAABAGKJtok1G9Uk1HAAAAABAGbKYDIPwMTu+ksqoa0zEAAAAAhDBGNtFmXxSV6/CpKr2w6aDpKAAAAABCFGUT7fZ/7+01HQEAAABAiKJsokP+uW6/6QgAAAAAQhBlE2228qeTXdsPfbRPh09VGkwDAAAAIBRRNtFmSXFWj/2n1xcYSgIAAAAgVFE20WEvbD5kOgIAAACAEEPZRLu8cP040xEAAAAAhDDKJtplQLckvf+T80zHAAAAABCiKJtot+R4m2u7oLjCYBIAAAAAoYayCb94d1eR6QgAAAAAQghlEx1y0bB0Sc4lUGb8bY3hNAAAAABCBWUTHXLNuD6u7eIKuyrttQbTAAAAAAgVlE10SJekOI/94gq7oSQAAAAAQgllEx3SIyXeY7/OYSgIAAAAgJBC2YRf2WvrTEcAAAAAEAIom+iwt2+dqF/NHCJJqqZsAgAAABBlE37QJSlOXTvFSpKqa7mPFgAAAABlE34SZ3X+VmK9TQAAAAASZRN+crraueTJ058WGE4CAAAAIBRQNuEXFovpBAAAAABCCWUTfjFtUHfXds7iVfp/r+5QWVWNwUQAAAAATKJsIiDe++KYpv/1Y9MxAAAAABhC2QQAAAAA+B1lEwF1rKzKdIQ2q6qp0+L396qkwm46CgAAABC2KJvwmzW3T9GdFwzyOPY/y3aops6hnMWrlLN4laFkbfP69iN6fuNBPbjyS9NRAAAAgLBF2YTf2GIsuuLsXpozpqfr2PYjpZr0wIcGU7Xd3e/ukSS9tr3QcBIAAAAgfFE24XcLLhysl2/IMR2jw8b2TjUdAQAAAAhblE0ERNekWNMR2uX+9/a4todmJBtMAgAAAIQ3yiYCIinO6vW4vbYuyElab+uhU1q66ZBr330bAAAAQNtQNhEQMRaLx/73zu0tSTrvwY/01s6jJiL5dONzm5scq3M4DCQBAAAAwh9lE0HxX7eC+cs3PjeYpG2OlVWbjgAAAACEJcomAuauWcMkSQ9+e6RsMZ4jnY4QHjEckZni2p792DqDSQAAAIDwRdlEwFw8PEPv3DpJk7O66oV54zxee3ztfkOpvGsov5MHdNWS759tOA0AAAAQ/iibCKi0+llpO8XZPI6v+eqkiTjN+mR/sSTpQHGFJEXE0i0AAACASZRNBE1WtyTX9rbDpwwmaeonL22TJO0/6Syb/bokul4rqbAbyQQAAACEM8omgmbp9eO09vYppmN4qK1z6NqnN7r2H71ydJNzVu45HsxIAAAAQESgbCKorDEWZWemaNJZXUxHkSRd8c9PtbOwzLV/Tp+0Jue8uJn1NgEAAIC2omwi6DrFWVVWVWs6hqTG22a9aZhA9/OjZTp5miVQAAAAgLagbCLoOsXbtLOw1HQMn74xqLtr+7v/+NRgEgDeVNhrlbN4lfYeKzcdBQAAeEHZRNAdLa1STV3orbN548R+Hvt/mD3MtX2qsiak1wYFotHUP6+WJF21ZIPhJAAAwBvKJoJu+xHnqObmghKjOc4sj0PSO3ns26wxHoWTiYKA0LHtUGjNaA0AAJqibCLo6h+F1KaDZsvmaXvjc6NLrz9XFwxJb3LOzGEZOrtPZ0mSzWpp8joAM254brPHPnceAAAQeiibCLrvndtHkvS3j/YZzXG83Ll+5kXD0pXVrVOz5w3LSJYk/X3N/qDkAtB2Gw3fKQEAAJqibCLo5k3oK0maaHj5k/tWfNGq82YMdY54llba9e6uokBGAtBOP3xhq+kIAADgDJRNBF3nxFhJUr+0RKM51n1dLEn67pheLZ7XcPvsgeJK/eK1ndyuBxh25FSla/tXM4cYTAIAAFpC2YQRvVLjVV5dYzqGJGl079QWX0+rL8cNqmrqAhkHgA/uk3VdOiqzVe/ZcKBYL24+FKhIAADAC5vpAIhOSXE2lVfX+j4xAOy1daq0NxbGGEvLE//0TE3w2D9SWqU/rfxSVTV1+tvlowOSEUDzEuOsbTr//vf2aOkmZ9Hs1yVRE/r7voX/wMkK9UlLkMXH3w8AAKB5Psvm4cOH9fOf/1zHjx+XxWLRFVdcoeuuu04PPvigVqxYoZiYGHXr1k133323evToEYzMiAB7jpVrj6GF2H/y0rYOTSZy+T8+dW0fKqlUr84JLZwNwN8aRjb/PGdkq85vKJqS88//+vlTWzx/U0GJblm6Rb++aIhyR7Zu5BQAADTl8zZaq9WqBQsW6I033tDSpUv17LPPas+ePbrpppu0fPlyLVu2TN/4xjf00EMPBSMv0GHtKZpPXj3WtQ7niMwU1/G8xz/xWy4ArbNqr7NsZiTHexzffbTML9ffd+K0JOm9L4755XoAAEQrn2UzIyND2dnZkqTk5GRlZWWpsLBQycnJrnMqKiq41QjtUlNndrKdvmmtG5Uc1StVT1w9VpK040hpICMBaKUeKZ5l89kNBU3OqT3j75hxfTv7vK41xvnv2UdfnuhAOgAA0KYJggoKCrRz506NGTNGkvTAAw9o2rRpWr58uX72s58FJCAi0x3TB0qSyqrMThL0yo3jW31uvM37Hxf3mTEBBFad22zQneqf3Zwzpqck6fUdR5ucX13rOaHXpwd839nAJGAAAPhHq8tmeXm58vPztXDhQteo5u23366VK1cqNzdXTz/9dMBCIvIkxTp/672+vdBwktZrbvT+DS8fcAEExqGSxi93Gv5MTh/c3XWsuMLucX6l3TkR2Z0XDGz1zyitDI2ZsgEACHetKpt2u135+fnKzc3VzJkzm7yem5urt99+2+/hELkaPjA+uPLLoP7cnMWr/H7NTQfbP9kQgLapqC+PCy4c5Do2vl+aa3vG39Z43Dq795jz+csdhWUa17ezBnRL8vkzXt7SOKGQ6bsvAAAIZz7LpsPh0KJFi5SVlaV58+a5ju/bt8+1vWLFCmVlZQUkICLT1IHdvB4vq6rRit2LlxzMAAAgAElEQVRFAfmZZz679ZdWzmTpzYf5k/XX746SJK3dd7JDuQC03nMbDkqSNh885Tp25l0Hp92WVXrs432SpE6xVnU+Y83c5hwtq3Zt89wmAADt57NsbtiwQcuWLdPatWuVl5envLw8rVy5UosXL9Yll1yi3NxcrV69WosWLQpGXkSI4W4zuh4rq3JtT//rx1qwfKf2FHVsWZQvisqUs3iVx6jExAc+dG3/4Lz+mnhW1zZfd/nN43XfpSOUEGtt1Vp9APxrTO9USdKlIz2X2nrx+nGu7ZJKu5765IBq6hzaVF9KE2JjZIuxyF7b8vOYZ9798Pbn3CYPAEB7+Vxnc9y4cdq1a1eT49OmTQtIIESHGLeRiG89uk7r50+Vw23ij9J23rr25Nr9enj1Ptf+9L9+rPXzpzYZ1bx+Qr92XT8zNUGZqayrCZgSb3NOCpR+xrInZ7ndHvvtJ9ZLkv7y4VeuY3Nz+urPK79UQXGlDpZU6MVNh3XJyB4a1L2T6xz3yYcamJ4xGwCAcNam2WiBQNridltcQXFFu67hXjTdnTzdeFvc1ef0li3GP0v13DChrySpxsdoCQD/qKpx3iKb0Mzs0M1JS4zVofqZoy97fL2e2VCgq5ds8DinyO322QZruE0eAIB2o2zCmDd/MMFj/54VX7i2f//WbknS/pMV7S6e7tZ+3fiBMTM1voUz22Zl/eLy7tcHEDgNy5Ik1I9wumv48qc5G3wse7LnWOPt+/++Mce1farS7u10AADgA2UTxnRPjte5fTvr7PpnsL4+4VkqX9l6WHOeXO+6Ja4j0uonBunVOUF5ozI7fL0Gt0zqL0lKimv6wReA/zWUzfjYpv983Tixv9f3TDyr+eer3W+T/eJomWu7T1qia3v9/uI25wQAAJRNGLbhQIlrAo+bJ3l+ULz7nS+8vaWJTQUl+s2bn3t93iojOU6StO5r54fF3108VJ3ifD6q3Gq9Ozs/kP5g6VblLF6lkgpGQIBA+KKoTDc8u0n//OSAJCney220cbYY/XLm4Gav8dHPzm9yrGEdTkl6bM3XXt/36GrvxwEAQMsomwgJ9to6VdbU+j7Ri1tf3Ko3dhz1+rzV0bJqHSyp0PMbncsldK8vn/7SJclzKYXHPuZDKRAI33tqo7YdLtWpSufkYTEW789d543qqdVnlMqG5YnibTG6YHB3j9fcl0mx1zq/sHJfw1OSvjpx2uuXWS3ZcKBYOYtXaWdhaZveBwBAJKFswqgh6c6ZIH/33136x7oDzZ7nPsHPmRpmmv20mVvd/vftxhHSmlr/zizZ9Yyy2bdLYjNnAmivtha9uBYmD7o7d7h+MWOwfnPxEEnSaXvTL7kaRk3dZ6otrWzbDNk/fmmbJOnapzdpzT7W6gQARCfKJow6UD/5z1ufF7V43pPNFNHqmsZZYH/7X88lei4ali5JGtEj2XWsX1f/lkGb1fOP0GvbC/16fQDSwtd2tvk9y24a7/V4jMWi74zuqZR45xdFFfVl033ppQsGO//ueObac1zH7luxp00/3325pfyXP2vTewEAiBSUTRj1q4uGNjn23x9OdG03jHw+v/GgvjxerpzFq/TOrsZiOvlPH3m97vAeyfqfC5y3wrnfJtfcrXcd8eYPJ2ruuD6SpF1uE4wA8I8Vu4+1+T29Oifo8avGSJJ+fdGQJq8nxTn/+bv26U367PApffhl4+hjnNX590SMxaL50wdKkt7e1fIXYgAAoCnKJoyaMTS9ybFuneJ05wWDdO+lI/TbbzWW0Sv/6VwTb+FrO5WzeFWzt9YNSe+kh68Yrc4JzomAXtpyWJL0o/PP8nN6p+6d4pQ/Lcu1X1bVttvtALRNv1berj6md2etnz9VuSObzkCdFNs4g/S8ZzfroQ+/cu2737HQu3NCB5I2crTxVmAAACKB/6blBPyg4VmpK87uJanlZ7UWLPd+a90/v3+2Yq1Nv0c5VFLph4S+7Skq181Lt0iSlt88Xpmp/vmwCsDppXnjOnyNwtIqj/3M1Hh9efy0/jB7mMfx8f2bXzalOX/76Ksmxz7ed1KTB3Rt87UAAAhnjGwipORPHeCxH2OxqFsn7zPIvv9F01vr/jB7mNeiKUk/cxt9DKQl6xufL839+ydB+ZlApLLXOp/LHlx/S/3wHsmy+OF2+JE9Uz32h6Q7n+0e38+zXMbbYly31a7ae7xV1/Y22RnLIgEAohFlEyHlzZ1Hmxx75YacFt/z3TE9XdstjSImxwd2IP/CIc4lFT76kpknAX9peF7zi6JyrZ8/VU9dc46Pd7RO+hnLIDWs35kYZ21ybnX9LNbz/7Pd53W/PF7usd/w98Jv3tzl7XQAACIaZRPG/eemxjJ548R+TV5PirPqTbdJg870zq4irfzpZN136QiN7pXa7HmBNjenr7GfDUSqX73xeUCue+boaI+UeEmNt/K7++Nl2a2+bsOz5ZI0LCNZt54/oIWzAQCIbJRNGNe7c6L++f2zdW7fzsrp5/35qLSE5kcl7710hJLirJp+xmLtkpos4B5IIzJTvB4/WFIRtAxAJDnfbbbp317cdObqjnK/bb+wtKrZiYdy+qW1eJ06h0OO+v+5e+qas9UnrfFui0ova3oCABDJKJsICdmZKXrkijFeRxUk5+yQ6+dPbXJ8XL80ndu3+Q+CP55iflRhwattXyMQgFTlto7u7Owefr/+mXcjJMY2vYVWkhLcjucsXqXVX55wFcd73/1CE/74oWb8bY1H3v/clCOLxeKx3NIdrbgNFwCASELZRFj5MH+ynp7b+MzW8IzkFs/vlRof6EheZWem6Noc59qbLHgAhK7nrzvXtd3cl11nuu3fn+mChz5WYWmVa2mlksoavVc/adm4fmnq3blxlHRKlnMW2vX7i/0VGwCAsEDZRFhJiLVqaEay/vrdUZKki4ZntHh+w4iot1HRQNp+pFR5o5wTFwVryRUgkriPEt7+jcDNJD2weyfX9tZDp5o9zxrj+YynvdahSx5b53GsYRKgS0d6jsLe34ZnPgEAiCSss4mwNKF/F31yxxS/LIEQKA3LJZRW1RhOAoSfxz7eJ8k5Svi9c/uYDSOpf5dEfXn8dKvOPVHuucxJTAj/PQUAQCAxsomwFYpFs2GSosHpndQ5MdZ1/IEP9pqKBISUnMWrlLN4lcex2jqH1uw7oWPl1XpjR6HstXV6an2BJGnqwG4mYjYxN6f1hdfXhEIAAEQLyibgR8N7OJ8hnXRWF4/JRp7dcLDJuUdOVWr1V6zJiehhr228NdZ9Zta73t6t/Jc/07ceWavfvLlL5z3YOAttbgAmBmrO4hZud501ood6tvIZcG/PfgZigiMAAEIdZRPwo75pzklBsro5nwO7Y/rAZs+d+/Qm3fbKZ0HJBYSCzwvLXNt7629JfeCDvXp9e2Gz7+kU532GWH9qWCKppVHUGItFr9w4XpeNytTbt07U3HGNI52v3TJB7/34PF15di8tnDFY/bsmNXn/qQrnrbXVbs+iAgAQ6SibgB99c0h3PXH1WM0a4Zy46Opzejd7bnH9h09GNxEtbnhus2u7oWB6G/V3F4zb5f9wyXCt+PEkn+fZYixaNHOIuiTF6fKze7mO90iJV0qCTf9zwSB9e3RPr+89dMo5UdhLWw75JzQAAGGAsgn4kcVi0eheqV4/IJ+54HsDRjcRyRwOh256brM+3Hvc4/iLmw+FzCifLcai1IRY3ye6aeuIa1L9bfUPfPCl6pr5uwAAgEhD2QQCLDHW+cesqKy62XPer1+fD4g0T67bry2HTumO/2xv8lo4j/IlxTknc3e/nbYl9106wrX9h7d3ByQTAAChhqVPgAC7bVqW7n53j4or7MpI8T7ByM9f3RH0tUCBYHhk9dfNvvbGjqMe+xcM7q6cfmkanpmiQyWVOj+ra6DjtZstxqI1t53fZP3N5nRPbvyz/+pnhfrVRUMDFQ0AgJDByCYQYAn1t899/18bXcfcZ+UEoskNE/pqfP3SILuONk4Y1DM1XvdeOkLfHdtL2ZkpmjE03WNG51Bks8a06ZnS1AS+3wUARBfKJhBgZ85Meaik0mNphwYPf/RVsCIBxtx83ln6ZH+xx7G1t0/RqzdPMJQoeE5V1ri2+fMOAIgGlE0gwKpqaj32Py8sdW27L/7+5LoDQcsEBMPJ002fU7Z5ue20tbeiRhL+vAMAogFlEwiwQd07ubZr6hwqq24snxsLSkxEAoIi9++feD0+oFvjaH9Gclyw4gAAgCCjbAIBlpoQq8z6iYEKTlaooLjC9Vr/Lom6aFi6qWhAQDUs8THprC66P2+EPrljiiTp8rGNa1S+OC/HSDYT7s8b4fskAAAiCGUTCIKff3OQJGnr4VOKtzX+scsdmel6DYg0l43qKUlafFm2pg3q7ppMZ0RmiuucpDauVxnOpg3qrjW3nW86BgAAQcPUeEAQpMQ7/6jd9Vbj+nprbp/S5Pm1Y+XV6t6J2woRGeocDnVOsCnW6vm9pvsXLtHGZo3R9MHdtf/kadNRAAAIuOj9Fx8IouFuIzkNvE2Ucslj67SJ5zgRIb4+WaE6R9PjA7slNT0YRRJsMdp7jLIJAIh8lE0gCHyN5Fyb00eSVFvn0C1Lt6isqqbF84FQV1Nbp0/3F6vUy+9li8Wi9fOnav38qQaSmffmzqOSpCOnKg0nAQAgsCibgAFnjmn+eMoAj/3pf/04eGGAAJjkZS1ZePJWxIPt1c+O6LmNB03HAABEKMomYMCZdxbGWCxKiOLn2IBo8r1zezv//6mNRnM4HA7d9dZu/fH9vdpZWKoKe63vNwEA0AZ8ugWCZM3tU1pc+qCypi6IaYDg+NXMIaYjhJzenRNNR5AkTfnzatf2tU9v0lS3fQAA/IGyCQSJLcaiaYO662fTsrT85vE+zy8orpDD0TgGerCkQtuPlAYyIuB3l47KNB0h5Hx3bE/TESRJVXzBBQAIMMomEGTXjOujzNQEn+d9+4n1emXrYR0trVKdw6HLHl+v65/ZFISEQMe4f0mCpmIsjU9tP7/xoOoC+OtVXVOnBz7Yq5IKu8fxM/cbnDhdrTqHgyIKAPALyiYQIrzdbnjPu3s0+7F1+t5TG1zHKnmuCiGuwk5Raa3F7+/VhD9+qMLSqoBc/51dRXp2w0Hdu2KPx/HHPv7a6/kXPbxWE/74oc7/00d8aQAA6DDKJhAickf20NLrz9UL149r8pr7mnxv7CjUTc9t5oMgQtb6/SclSaN7pRpOErr6dfF8bvOSx9YF5M90w6Q/7+wq8jieHG/1+d65T3MnBQCgYyibQIiwWCzK6tZJ6clxLZ5397t7tOXQKT2xdn+QkgFt80VRuSQpOzPFcJLQNXNoepNjSz454Pefc6y82rV9vH77WHm1EmOdZfPB74xs9r27jpb5PQ8AILpQNoEQ0ynOqmtz+vg879FmboMDTGsYtbtsNJMDNeey0U0nCXroo31+/znuX0oten2nausc+tYja10/a3TPVK25fYo++Ol5fv/ZAABQNoEQY7FY9NOpWT7PmzawWxDSAG1XUlkjSUqK9X2rZrTqkRIf8J9RW+d5W+7B4kpNfOBDj2NxthjZYizqFGcLeB4AQPShbAJhauXe46YjAF7dVz8ZTXI8BaYls0ZkaOGMwVo/f2pArn+q0nPG2SNeJiGKt/ExAAAQOPwrAwAIiKQ4RjZb8rtvDdO3z7id9sTp6mbObruZD69t8fU+aZ5LMP10yoAm55w5OgoAQFtQNoEQd9+lI1zbN0zs1+T1ZzcUNJlpEgiWDQeKPQpJWVWNa9t9PUm0zkubD/n9mg98O9u1bY1p/G9yXU5fj/OuPre3JOdawA1++99dfs8DAIgelE0gRH2YP1lv/GCCpg/urp/Ujzh8/9zeev8n52n64O4a2D1JB05W6IEPvtTC13Y2e53aOodufG6zNhWUBCs6osS6fSf1wxe26ht/We069uVx5zI91My2eezKMZKkEX6awdde27jW6YT+XVzbDV8MPH7VGF06ynMCp1hrjNbPn6qfTcvSj84/S5J08fAMv+QBAEQnyiYQohJirUpPdk4ict34vlo/f6pSE2KVHG/T2n0ntPfYad33XuNC7TXN3O727q4ibT10Srcs3RKU3IgedXL+nqusaSw2Nz63WZJ05Tm9jWQKV50Tnc+3rt130i/Xu+2Vz1zbsdYY/fybgzxeH9O7c4sjz+cN6CpJsrv9twUAoK0om0AYqrA7PwC6fzBd/tkR17bD4dC6fSdVXVOnX77xedDzITpUuxWRix9Z6zGa9vzGgyYiha2G4rd0k39uo/1kf7Ek6RuDnLNWXz62V5ven1A/cdBG7ogAAHQAZROIEJ983Vg83/vimH7y8jb99OVtBhMh0r205bBr+3h5tX7gNnp+16xhJiKFrfTkOL9dq8at9F/lZYQ5oxU/KyXBOdL63MaDHl8qAADQFpRNIAw9efXYJsfe3X3Mtf3+F87tM0cljpe3babLv6z6Sq9uO+L7RESl8+tvtWyw7XCpa5tn/drGn+tcTnrwI9f2mF6pru2U+qVoyqpqfV6ja1JjIV1fP0oKAEBbUTaBMDTK7QOku5IKu1Z/eUJvfe59dtqLH2l5KYQzPbX+gO56e7dWf3mizRkR+Zp7Tvjcvp2DnATNsVkb/5m/brxz9tk5Y3o2d7pX/2/5Dr9mAgBED8omEKaevuYcSZ63xO0oLNVt//6sube0WllVjZ5cu9+1749rIvI0tybkWV2TgpwkshSftgfkuh9/5fzS6MVWLq+SlhgrqfkvFQAA8IWyCYSpoT2S9c6PJunfN453TQKS/7L3UvjWrRPbdO2fvLRND6/e19GIiGCnKu16an2B19cuGsYttB0x4+E1HmuXttfDl4/22J860Pn3hPs6mi1ZdtN4SfJLFgBAdKJsAmEsLTFWcbYYXToys9lzzu6dqq5JcRpQP9r08Edf+bzu9iOlTY5V2n0/54XIV15do5V7jumbD61xHXvr1ol690eTXPuxVlbZ7KgZf1vj+yQfxvVL89i/8pzeeuLqsbrlvP6ten9CLB8RAAAd478ZCQAYc3afps/IXX1Ob90xfWDjgfrP/0+uOyBbTIxubuUHzgbPbzyo6yf060hMRIBv/OXjJsfcJ5ORpJE9vT9TjNYrrarx+zVtMRaNbuZ5b2/c1+GsrXPIGsOXCACAtuFrSyACJMd7fm/01q0Tdds3sjyO3TSxsSg+tuZrr9eprXPoL6u8j3w+x7qJ8KJXarxre/38qVo/f6rBNOHtuevO9Xp86caD2nusPMhpPDX39wIAAC2hbAIRwn09va5JcR6jEpI0Y2i6x/5nh0957DscDk184EM9tf6A1+ufCNCkJQhv91w6wnSEiDGoeyfX9vTB3SVJRWVVuv/9vbpqyQZTsSRJz2zwfD73F8t3avpfV2vzGcsrAQDgjrIJRIj50we2OLJksVi09vYprv15z25WSUVjgfzHOu8lc9GMwf4NirB2QX0JkqRHrhit4T1SDKaJPOvumKIEW4y2HXJ+GTTr0XWu13IWr5LD4VCFvVZ/eHu3TlU2/QLorZ1HA5pvy8ES5SxepXd3F6msqlY3L92iOodDdy7brg0HWI8TAOCJsglEkTOfuVq66aAOllRIUpPZZ/931jC9fEOOLhvdtjX5EHlOVdr16rYjqqqp08b6kawfnX+Wzu2b5uOdaKsYi0WVNXU6Vu59WZnxf/xQr2w5rP9sO6I/fvBlk9d/+cbnfs3j/uVVzuJVuun5LU3OOXKqSh/sOa75/9nu158NAAh/lE0gytwyqXFioL+v2a/LHl/f5JyfThmgi4ZnqF+XRI/j+09WBDwfQs83H1qju97erfP/9JGK60fD5zFZVMCVV3ufJOiR+i+GXt9e2Ox7H79qTCAiebVy73FJUnk1M1YDADxRNoEoMyKz6W2P+S9vc22vu2OKrh3f1+t7/9XM85wA/M/bzL+SVFlT59q+9cWtXs8Z07vpDNXt5W22a3d/fH+v334WACCyUDaBKJMUZ21ybM2+k67tMycWkqRRPZ0F9T/bjgQuGIA2+3R/cbMjoP6Sm92jybEJ/dP064uGBPTnAgDCH2UTiDKx1ubXyvvplAFejz9yRfBuyUNoWbvvhOkIUeeacX089ied1aXF8xtGQMsCsDanJPVIiffYf/DbI7X4spF+HT0FAEQmyiYQZdxHNs9c12/pJu9racbZ+KsiWt397p4mx+5juZOA+skZX/oM75GsX84crEeuGN3i+65/ZlMgY0mS/vSdkZqc1VXxtpgmz3R37xQX8J8PAAgvfIIEokxWN+dafnPH9fFY109quVROHtA1oLkQmg6VVDY5Nt1t+RP4nzXGotlut67OzemrvFE91btzgsd5H992vsf+geLATOCVGNv4BdWY3qker/39ysa7HqrcniUFAEBqRdk8fPiw5s6dq1mzZmn27NlasmSJJOnee+/VxRdfrNzcXP34xz/WqVOnfFwJQKhYP3+q8qdlSZLe+/F5ruOXeHk2q8Gg9E6KtVpUUFyh7z21QRV2Zp6MJgO6JenmSf301q0TTUeJCkn1BS/BFqPkeJskuf5fcv4ZjrXGKDm+sQjWOZz/v+ym8X7NMtxtUrFOcTaP18b26az186dq3oS+Om2vlcPh8OvPBgCEN5uvE6xWqxYsWKDs7GyVlZVpzpw5mjx5siZPnqz58+fLZrPp//7v//Too4/qzjvvDEZmAH6UktD418C4FtZNTIyNkb3WoW8/4Vwq5en1Bbr5vP7Nno/I8ufvjFRmaoLvE+EXDaOJ7jPPJsfb9NuLhyohtvF74u+M7qnnN3re/t6rs3//O9liLHry6rHqntz8bbI7jpSqts6h4gq7uiRxOy0AwMnnyGZGRoays7MlScnJycrKylJhYaHOP/982WzOD6ljx47VkSPMUgmEqzW3T9FL88a1OOHH1yc8b9F7bM3Xylm8SruPlgU6HgypcxulomgGV1Kc93+eZ2f30DeHpLv2E2Ktqq51qDrAt7CO6pWqni38Hlj3dbEk6VdvfB7QHACA8NKmZzYLCgq0c+dOjRnjOTPlyy+/rKlTp/o1GIDgscVY1L9rUovneFkRRZL0v2/vDkAihIKismrTEaKW+3OSLSmpsEuSnly3X3FWi8b0SvXxjsCYNSJDUmPpBABAakPZLC8vV35+vhYuXKjk5GTX8YcfflhWq1WXXnppQAICCA2nq70/o3nmsgiIHPZa52jZdeP7Gk6C5ljqvwV6Yu1+Vdc6tOWQmfkT3EdbAQBo0KqyabfblZ+fr9zcXM2cOdN1/JVXXtEHH3yg+++/3/UPHoDI9LNpWUqJtzVZ7uCDPccNJUKgNTwLONJtghgExzOfFrTqvKEZnXyfFAQNa4GO6snvFQBAI59l0+FwaNGiRcrKytK8efNcx1etWqXHH39cDz/8sBITE1u4AoBI0CctUe/95Dy9fEOO6SgIsPLqGuUsXqWlmw5Jkr44Vm44UfS5eHjzM0O7uyQ7M8BJWifWGqOM5DgN6Nby7fgAgOjis2xu2LBBy5Yt09q1a5WXl6e8vDytXLlSd911l8rLyzVv3jzl5eXp17/+dTDyAggBr90ywXQEBNCBk56TQTWMWiF45o7r0673rfjxJD8nab3y6lptPsgyaACARj6XPhk3bpx27drV5Pi0adMCEghA6OuREq/186cqZ/EqSdLx8mp168RyB5Fi7tObPPZH9jQz6Uw0S0uK1WNXjlFWK0YKrxjbSy9sdo5CpybEBjpas8qra1VeXeH7RABA1GjTbLQA4M0He46ZjgBEnLP7dFbnRN/lscLuffIuAABMo2wCaLd7c4dLktISY3XgZIW2GZoJE/6z40ipx/6/rjnbUBK01vLthaYjSJLyRjmfH3VfnxUAEN183kYLAM3pV782511v7VZ5/dIo6+ez5m64qqmt03XPNN5Cy3/L8PDDyf31yOqv9YsLBxnN0S/NOVlgdU2dElq5TigAILJRNgG0W1L9B8ryZtbgRHg5ftru2h6cHhpLasC3Gyb001Xn9FanOLP/pO8vdj6vWVxhVyZlEwAgbqMF0AFMChRZKty+NFg0c4jBJGgLi8VivGhKzqXSJKmorNpwEgBAqKBsAmi3eFvTv0J4Xit8lVbVuLazM1MMJkE4Gprh/D1z//t7DScBAIQKyiaADrlwSHeP/Up7naEk6KiGsvnE1WMNJ0E4Soh1fqQ4c5IpAED0omwC6JDfzxrmsX+6uqaZMxHqttbPJpzE83ZohxlD0yVJA7v7XhsUABAdKJsAOiTWGqNV+ZNdi8+/v+e44URor+2HnSNS3m6PBnxJjLWqd+cEZXVjcikAgBOfKAB0WGKsVVee3UuSlJkSbzgN2mtUL+czd706JxhOgnDVKc6qL4rKTMcAAIQIyiYAv+ie7CyZb+48ajgJ2qusqlad4qyyxlhMR0GY2l1Urn0nKnTyNDPSAgAomwD8JCPZuQzKO7uKDCdBe5VW1Sg53vwSGgh/961gRloAAGUTgJ8MzUh2bR85VWkwCdqruMKutMRY0zEQxvKnDpAkvbu7SBX2Wh9nAwAiHWUTgF9YLI23Xj6z4aDBJGivDQeKFWflnwW0X8OMtJL03u5jBpMAAEIBnyoA+N3Y3qmmI6CNKu21qrDXadvhU6ajIIz1cJsg7Lf/3WUwCQAgFFA2AfjN09ecI0lyOAwHQZtN+fNq0xEQAdzvcAAAgLIJwG86xVslSZ8fZemDcDWwe5LpCAhzn9wxRZI0oX+a4SQAANMomwD8puF5vyWfHDCcBO31u4uHmY6AMGexWHROn86qruUWBwCIdpRNAH6TksCyGeGqX5dESdLQHsk+zgR823usXJsKSvTshgLTUQAABlE2AfhNYqzVtb1m3wmDSdAWf/voK+0/WeEqnEBHlVTWSJIe+OBLw0kAACZRNgEERP7Ln5mOgFYoPm3XP8q3GMUAACAASURBVNY5b3vef7LCcBpEooJifl8BQLSibAIICCuTUoaFWY+tNR0BEWhV/mTX9refWK/j5dUG0wAATKFsAvCr5TePlyRdMjLTcBK0hp1JXBAA7rfUS9J3/7HeUBIAgEmUTQB+lZmaIElatu2IHCy4GVZy+rFUBQKjrKrWdAQAgAGUTQAB8+9tR0xHQBv8YTbLnsB/Fs4YbDoCAMAwyiaAgPnnuv2mI6AFdWeMPHdJijOUBJHogsHdTUcAABhG2QTgd3PG9JQkHT5VZTgJWlLOrY0IoM6JsfrPTTmKtzk/anBbPQBEH8omAL9bcGHj7XNHS6t04jQzUYaiU1V21/Ytk/obTIJI1btzor4z2vnlU1VNneE0AIBgo2wCCKjZj63TRQ+zvEYo2nCgRJL0s2lZumlSP8NpEKn6dkmUJBVX2LVyzzHDaQAAwUTZBBAQ45nZNOTd9dZuSVJ2ZoosFhZGRWB8dfy0JCn375/of5b9/+3dd3xUVf7/8fekJyQQAgk1lFAEqYqhi4oUBVmwr666ImtXFmH97ipff1u+lm2oa1lF167sWsFVrIBI7703KaEECCmkt/v7I8lkJjOTTJKZuZmZ1/Mfz733zL0fMMzjfnLO+ZxdWn800+SIAAC+QrIJwCsiwvh68Rch5JnwopgI+z03T2QXmhQJAMDXeBsE4BUrDp2zOy4tpzhIU1JYUl0cqFebOBMjQaAb09O+Ku2ivUylBYBgQbIJwCeKKQ7SpOw/k2dtRzIKDS+q+cuMsFCG0gEgWPCGAcArpg21LzhzKCPPRU+YoWqJ5gMju5gaB4JPzVkPAIDARbIJwCtuuqi93fG+MySbTUlOYakkqV+75iZHgmDw2NgedXcCAAQckk0AXpEQE6FfDOqoWwd1kCStYjSjSfnPpuOSJEOspYX3Te7bllF0AAhCJJsAvGbG5Ska1qWlJOnHgxkmRwNbvdrESpL6t29hciQIBqEhFk0d0kkjUxIUHc6rBwAEC77xAXjV2bxis0OAEyVlhiLDQigOBJ8qKi1XQQnFwgAgWPCWAcCrLupYPXKWV1xqYiTBKbeoVKlzlmnexjS7859uPaEiKgTDx9YfzZIkLdyZbnIkAABfINkE4FUdWkRb2+cLSTZ97Ya3NkiSnlt6SJn51aPMjC7BTBuPZZkdAgDAB0g2AXhdaqd4SdKk19dp/5lck6MJLhk205jHvbJGkpRTWGJWOAhyvSvXCn/ByCYABAWSTQBeN6Zna2v71nc3mRgJJOmP3+wzOwQEqUu7tTI7BACAD5FsAvC68b2TzA4BksJCLJKkZVQGhknaNY80OwQAgA+RbALwuujwULvjcoO9HX3hWGaB3XFpOX/vMFe75lFmhwAA8CGSTQBeF2Kx2B3vPc26TV9IP1/kcG7488ut7c/uSvVlOIBddWoAQOAj2QTgE8unj7C273h/s4mRBI/7P94mSbpvRGfruZKy6tHN5JbRDp8BvKnmL54AAIGNZBOAT0SFhyqE90xTXNSxhebdcbHZYQCSpP7tm5sdAgDAR0g2AfjM8ukjzQ4hKF3cMV49EmPtzk0dkmxSNAh2l6YkSJJyi9h3FwACXZjZAQAIHhFhFb/f6pHYzORIgtsPDw1XbCRf/zDHgbN5kqTVhzM19oJEk6MBAHgTbxsAfGpQcguVllEV1dteXPaTw7mF9wyRIZFowlRXX9hG3+45o6TYCLNDAQB4GW8cAHwqPjpcBytHNuA9764/5nAuKY49DmG+qMoZDsVl5SZHAgDwNtZsAvCpw+fydfhcgQz22vSq3m0q1miOrFwfBzQVUZX77haWkGwCQKAj2QTgUwfP5ktyvgckPKdq9OivP7vQ5EgAe1U/m4WlJJsAEOhINgGYYv72U2aHELD+vem4Nh/PkSSFh/I1j6YlsjLZLCotMzkSAIC38RYCwKf6touTJC3cmW5yJIGpsKRMz/5w0OwwAJeqptEWMI0WAAIeySYAn/rNFd0kVUyjZd2m5329+7TZIQC1ahZRkWzmFzOyCQCBjmQTgE+1jKne7iC/hJdNTyuyWQf3zDW9TYwEcC4qLEShFim3qNTsUAAAXkayCcCn2jWv3n7jzTVHTYwkMNmObI65INHESADnLBaLYiPDlMfIJgAEPJJNAD5lsVjUvjLhfHd9miQpdc4ypc5ZptJyptU21q5T5yVJf57EqCaarmaRYYxsAkAQINkE4HN/ndzH2rZNMJ/8dq8Z4QSk0T1amx0C4FJsRCjJJgAEAZJNAD7XrXUza/tEdqG1vXAXxW08xWKxmB0C4FJkWKiOZBaYHQYAwMtINgH4XFiIRT0TKxLO699cb3I0geOrXWwnA/+w/WSOjmYW6Pmlh8wOBQDgRWFmBwAgOO07k+dwbiwFbRrk6lfX6GxesdlhAPX2wcY0zbg8xewwAABewsgmgCbj+71nlJlP0lRfNRPNGwe2NykSwD3//uUgs0MAAPgAySaAJmXcK2vMDsHvXde/ndkhALXqbrNuGwAQuEg2AZhiTE+mzHrDo6O7q3siL/LwH/O3nTQ7BACAl5BsAjDF5H5trO3501Lt1mt+s5uqtO6quX1Eu8o9TAF/8fT3+1VaVm52GAAAL6gz2Tx58qRuv/12TZgwQRMnTtQ777wjSfr66681ceJE9erVS9u3b/d6oAACy5DOLTXrim76/v5h6hgfraev6W299udF+02MzL9c8dIqu+OLk1uYFAlQP9NHdbW2H/3vLhMjAQB4S53JZmhoqH73u9/pq6++0ocffqh58+bpwIED6tmzp1588UWlpqb6Ik4AAcZisejnF3dQfEy4w7W84jITIgoMzSIoMg7/YFvIat2RTBMjAQB4S51vJUlJSUpKSpIkxcbGKiUlRenp6RoxYoTXgwMQXJY8OFyjX15Vd0c4+PHhEYqJCDU7DMBtUeHVP6/FZYbO5BYpMZZp4AAQSOq1ZjMtLU27d+/WgAEDvBUPgCAWF8WoXH1d1bvil4EkmvBHSx4cbm1PmLvWxEgAAN7gdrKZl5en6dOn6/HHH1dsbKw3YwIQxC5hzWG9RIeHqDlJOvxUzV8w5RWXuugJAPBHbiWbJSUlmj59uiZNmqRx48Z5OyYAQWzDsWxJ0vlCXjrdcSyzQBazgwA85PIXmUYPAIGkzmTTMAzNnj1bKSkpmjp1qi9iAhDEqrZAYe2me07mFKmwlG0j4L+eGNfT7BAAAF5SZ7K5ceNGff7551qzZo0mT56syZMn68cff9T333+vUaNGafPmzbr33ns1bdo0X8QLIMClZRVY24Zh1PvzO0/m6P0NaZ4MqcnKLijR8exCFZFswo+1bxFldzzm5VU6llngojcAwJ9YjIa8zbnpzJnz3ro1gAA1dd5m7ThZ8d3Rp22c3rp1oCwW9yaKTvnXOh3PLpQkrZ81ymsxNhWzFuzUsoMZkoLjz4vAtfNkju6ct8XuHD/TAOAfEhPjXF6rVzVaAPC2uTdVV7veeeq8vtyZrtQ5y5Q6Z1mdn61KNCWppCzwR/uqEk3A3/Vp11y3X9LR7DAAAB5GsgmgSYkIC9Fbtw60Hv/p233W9nNLD2rhznR9vOWEw+f2pufaHW88luW9IJuYe4Z3NjsEoNEW7ko3OwQAgIdRLx9Ak9OqWYTT8/M2Hre2x/RsrZYx1f3eWX/Mrm9WQfBUs20TF2l2CECjvXB9P9323iazwwAAeBAjmwCanGYRoXX2eXnFYbvjdUcy7Y6f+GqPJ0Nq0i5NSTA7BKDRurWKsTv2YkkJAICPkGwCaHKiw+tONj/ffsruuEV0uLfCafJsR3gBfxUWav9KQpVlAPB/JJsAmpzwGi+dkWHOv6peWXnY2j4aZFsllBuGLJLuGpJsdiiAx9hWoP1u7xkTIwEAeALJJoAm78t7hkiSeiXF2p1/c81RSdKPB85az8VGhqp/++aSpLziwF23mVtUKkNSbCRL7xFY/t/4npKk0nKm0QKAvyPZBNAkrZ4xUq/e1F9v3TpQ8dHhWj9rlN67/WItfXi4Xb9yw9D8bdVTan94aIS2nciRJN389kafxuxLLy77SZK05nBmHT0B/9IjsZkk6Znv95scCQCgsUg2ATRJYaEhGpQcr77tmtudbxYRZjfV7v99tUf7z9hve3LzRe0lSenni7wfqEkWVK5ZdWd9K+BPLqgxg+GrXek6eDbPpGgAAI1BsgnAr32754xO5xZLki5JbiFJ+nBz9T6cT9rs0xkobKt0zrg8xcRIAM+zWCzWdm5RqX7/9V79/J3AnaUAAIGMZBNAwJg1urskaUjneOu5z3ecctXdb723Ps3aZo9NBLL7P9pmdggAgEYg2QTgl8ZekChJCq0eBFGn+GhJFZvDB7IXl/9kbdes3AsEgsn92kqS9pzOraMnAKAp4y0FgF96+prekqQym4KVEZVbpIRYLAq3zUIDVGwk6zURmPaRZAJAQCDZBBAQ7hnW2e74+weGWdvn8ot9HY5P/PHqXmaHAHjF7nTHZLNqqyMAgP8g2QQQEK4d0M7uuFlEmLomxEiS7vxgsxkhed2obq3MDgHwiicnOP4i5ZWVh+2KYwEAmj6STQB+y7Y4TnS449dZ1bTakzmBuwUKEIjG9Up0er6gpNzHkQAAGoNkE4Df+uPVF1jbMU72m3x0dDdfhuMT5ZUjO22pQosAZrv9ia3r3lyvtKwCH0cDAGgokk0AfmtQcvUWJ85eTgd0aOHLcHxi+cEMSdKp84zWIrB9ec8Qh3MZecW69o31JkQDAGgIkk0Afm39rFFaP2uUy+tDu7TUhW3jfBiRd2UXlkqSOsZHmRwJ4F1t4iK1ftYovX/7xQ7XUucs08qfzpkQFQCgPkg2AQS0NYcztevUeaXOWWZ2KB7RoUVFkvnYmB4mRwL4xgVJsbqufzuH8zM+22FCNACA+iDZBAA/cigjX5LULDLM5EgA35k2tJPZIQAAGoBkE0BAG5RcvW4zr7jUxEg846+LD0hyXhAJCFQJzSLMDgEA0AAkmwACWnx0uLVdVBo42ybERJBsIniEhVicrs3OLy4zIRoAgLtINgEEtN+N6aHurZtJks4X+v/IZhVn+4oCgW7uzf3tji97caVJkQAA3MHbCoCAFh8drumXdZUk3fbeJhmV+1T6I9vYY1mziSB0ccd4fXjnILPDAAC4iWQTQMDLzC+RJBWWlusvlWse/dHgZ5dLkh4Y2UUhLja9BwJdSqtmWvLgcLPDAAC4gWQTQMAb0KG5td3SZg2nPzlwJs/aDqTpwEBDxEVVj+yXlfvvbAUACHQkmwACXvvmUdZ2m7hIFZWW+9102jfWHLW2N6ZlmxgJ0LTsOnXe7BAAAC6QbAIIeBabKadPfb9fI/+xwjol1V8s2nfG2p55eYqJkQBNy8Ofbjc7BACACySbAIJCzSqW/iyKPTYBqzy2PwGAJotkE0BQuLhjvN1x33ZxJkXSMEmxEQqxSLGRoeoYH1X3B4AAN/HCJLNDAADUgWQTQFDq37553Z2akNO5xSo3pB8eGqFmEWx7Avzh6l5mhwAAqAPJJoCg8dy1fazteRuPmxhJ/ZSUlUuSUlrFmBwJ0LSEVC7HLqUiLQA0SSSbAILGyJRW6pnYzOww6i39fJEkaXK/tiZHAjQtVTnmrykSBABNEskmgKDywR2DrO20rAITI3HfvR9ulSS9s+6YyZEATdO6o1nafiLH7DAAADWQbAIIWtP+vcXsENxyOrdYkvTkRNaoAbYWPTDM2r7LT/49A0AwIdkEEHSiwyu++s7ll9TZt6CkTLe+u1F703O9HZZLnVpGS5IuSY6voycQXFpEhysukoJZANBUkWwCCDpLHhohSW6t39yUlq39Z/J02/ubvB2WS0czK6b7WiwW02IAmqolDw23th/+dLs+2nxcS/afNTEiAEAVkk0AQScsxKK+7eK070yefv/1nlr7zvhsh4+icu5sXrGpzwf8yZrDmfrbkoP67X936ci5fLPDAYCgR7IJICjFR4dLkr7adVqllVuL1MUwfLu9wpL9Z3X1q2t8+kwgUNzw1gb9e9Nxpc5ZptOVFZ0BAL5FsgkgKK04dM7aPpjh3ghIUal7Samn/Pa/u3z6PCDQPPvDQUnSxNfWmhwJAAQnkk0AQe+295yvxyyvMZJZtXYSgP958rt9ZocAAEGHZBNAUEppFWN37GyK7Kqfztkdv7XWN/tc7judqx9qFDj5/FeDffJswB/96+cDNL5XYq19Pt9+SufyWQMNAL5kMby4COnMmfPeujUANJphGBr87HJJ0ru3XaSeibFasv+sxl5Q8dKaOmeZJCk0xKKy8oqvyvWzRnk9rqrnVlk381Iq0QJuuPXdjSotN/RTLVPj+fcEAJ6VmBjn8hojmwCClsVi0ciUBElSZn6JpvxrnR7/crcmzrUvyjN1cLK17esKl49cnsKLMeCmeXcM0kd3XmJ3ruYWR9mFpb4MCQCCGskmgKD24MiukqT84jKdqqxYeTrXfqrdPcM7W9s3vLXBq/GczbWvmvnvjce9+jwg0HVrbZ9snswpNCkSAAg+JJsAglp0RMXX4GNf7raeS4qNsE6bleTTkcW84jK741sGdfDZs4FA8fHU6tHNe0d0trt2x/ubfR0OAAQtkk0AQS0uMsza7pUUK0m66aIOuuGt9Xb96io+4ikHz+bZHd86qKNPngsEko4toqztDi2i9cnUSzSqWyvruZqVpgEA3kGyCSCoNY8Kt7bzSypGFYvLypWWZT/V7u5h9qMj3hIZHmptj7vANwkuEGjCQu1fbzonxOivP7vQepxfYwYBAMA7wuruAgDBIb1yzWZxabn13COXp0iqeFmtsnT/WV3eo7VXYqiasPvGLQPVv31zrzwDCAZDOscrLrL6l0mhIdXT4TenZetSm5FOAIB3MLIJIOjNuKwioSyqTDLfXle9n6azaayP/neX12IprIwhKoyvZ6AxXrqhv56Z1NvptZkLdqrcMPTnRft1z4db9d2e0z6ODgCCA28zAIJeVHjT+SosKq2Y3hdJsgl4XNVMBUl68JPt+nTrSW1Oy9bshXtMjAoAAhdvMwCCXs31ma7YboFSWOKdNV+FJZUjmzZrNwF4RmqneGt7w9EsEyMBgOBAsgkg6KVlFTg9v3rGSLvjaUM7VX8m2zt79S07mCGJkU3AG3okxpodAgAEFd5mAAS95Phoh3NjerZ2qGgZYrFYK8S+sfqoV2JZceicJNZsAgAA/8fbDICgd8fgZEnS0M4treducbG/ZdU0vEX7zngllpEpCZKYRgt4S3ioxeGck1MAAA8g2QQQ9OKjw7V+1ii9eEM/fTz1Ej1yeYrLbUfG2Ox9WTXl1ZMSYsKVFBvh8fsCqPDZXanW9hPje0qSygwpt6jUrJAAIGCRbAKAjS4JMU63O6kSG1m9PfGsBTtrvdc/V/ykBz7eVq/n/3dHuk7nFtfrMwDclxQXKUmaPqqrfta3rfV8XrF3in4BQDAj2QQAL3lr7TGtP5qlhTvTzQ4FQKUQi0XrZ43S7akV0+enDqn4r2EYZoYFAAGJZBMA6qlHYjNJUrSb+3P+4Zu9Wnsks85+W49nS6I4EOBLVcs139+QZmocABCIeKMBgHp6bEwPSVJB5Z6Y7nh33bE6+/zqP1slSYWl7t8XQOO8ubbi3+aHm0+YHAkABB6STQCop342xYOyC0rc+sy6o1n61b+36Hyh8yIktlP4hnZp6bQPAM9745aBtV5f+dM5FfMLIABoEJJNAGiEMf9cLaliCt7u9PPW86lzljn03XoiR3fO2+z0Pu+ur57C9+L1/TwcJQBXbCtPn80tsrv20ebjmvHZDo34xwpfhwUAAYFkEwAaYFByC2v7fxfu1j9+PKQ73q9IJE/lFLr83NHMAqfnX1r+k2cDBFBv/1pzVGXl1bMM/rbkoLVNoS8AqD+STQBogOev7Wttf7vnjN21Sa+vq9e9cgrdm4oLwDtuu6Riu6NPt57U0OeWS5LKa1SnfWHZIZ/HBQD+jmQTABogKjzUrX4/PjxC86el2p17bulBu+MVh85Z21/cPbjxwQGol+sHtLM7/r9v92rIs8vtzl3YNs4hAQUA1I5kEwA8yPZl9Lv7hyomIlQd46O1+MFh1vPzNh63+0xYSMXmC/87rofaNo/yTaAArDrGR9sd/3eH45TZFYfOOSSgAIDa1Zlsnjx5UrfffrsmTJigiRMn6p133pEkZWVlaerUqRo3bpymTp2q7OxsrwcLAE3JO7+4yOFcWlb1es2WMRHWdvOocJf3mb1wjySpfQsSTcAs7u6beyLb9ZpsAIC9Or9ZQ0ND9bvf/U5fffWVPvzwQ82bN08HDhzQa6+9pmHDhum7777TsGHD9Nprr/kiXgBoMnomxeqSTvG6f0QXXVJZMOj6N9e77D+pTxtr+8DZPIfr/du3cDgHwDeWTR/p9HyHGr8Emvyv+q3JBoBgVmeymZSUpD59+kiSYmNjlZKSovT0dC1evFhTpkyRJE2ZMkWLFi3ybqQA0MSEhVj0yo39ddfQTnro0q519p8+KsXa3na8YjaIbeXLyDBWNgBmsi38VWVw53gTIgGAwFCvN5u0tDTt3r1bAwYMUEZGhpKSkiRJiYmJysjI8EqAAOAPak6B/cvPLnToEx8TrhZRYZKkZxYdkCSdyy/2fnAA3DIiJUHX9W+nrq1i9M19Q3Vlz9b6nyt7mB0WAPitMHc75uXlafr06Xr88ccVGxtrd81ischisXg8OADwFzER9l+no3u0dtrvvhFd9JfFFYnm8ewCRYa5V9UWgG88NrY6ufzzJMdfGgEA3OfWyGZJSYmmT5+uSZMmady4cZKkVq1a6fTp05Kk06dPKyEhwXtRAkATFxHq3i/chnet/q786+ID2nEix1shAfCQr+8bqtdvHmB2GADgd+pMNg3D0OzZs5WSkqKpU6daz48ePVoLFiyQJC1YsEBXXnml96IEgCbO3dkdttNtV/2UqUf/u0uSNKan85FQAOZr3SxCAzu2UMto11WlAQCO6kw2N27cqM8//1xr1qzR5MmTNXnyZP3444+65557tHLlSo0bN06rVq3SPffc44t4AaDJ++Gh4bVenz8t1eHcon1nvRUOAA/JLCgxOwQA8CsWw7DZgdzDzpw5761bA0CTc+BMnlo3i1B8TN2jH6lzltkdL3pgmFowagI0aU9+t08rDp3TN/cNNTsUAGgyEhPjXF5zu0AQAKB23RObNfizJJpA0xdqsSgjjwrSAOAuNnUDABPYrt1cP2uUiZEAcNdn205Kkk7lFJocCQD4B5JNADDBnMl9zA4BQD09OLKLJCm/pMzcQADAT5BsAoAJyiqXy/doxNRbAL5VNVX+5rc3mhwJAKli1wxmGjRtJJsAYIJurWJ0efdW+v1VF5gdCgA3ncunGi3QlHyw8bgmvb5OhzPyffK87IISPTJ/h87ls3bbXSSbAGCCsNAQ/W1yH12QFGt2KADcNLoH++ECTcnKn85JktLPF/nkeU98tUcrDp3TQ59slxc39AgoJJsAAABuiI0MU6eW0WaHATRK+vmigJl6Wli5fjos1OKT5x04mydJ2n8mT++sO+aTZ/o7kk0AAAA3Hc0skCTlF1MkCP7pmtfWatLr63Q21zejgd5SWm5ox8nzkqSXlx/2yTOv6F49u+HlFZ555q3vbtR3e0575F5NEckmAABAPb268rDZIQCNcvXctcotKjU7jAbbezrX2t5+Mkc7T+Z4/ZkfbTlhd/z17vRG3S+vuFT7z+Rp9sI9jbpPU0ayCQAAUE8tY8LNDgFotI9rJE/+5M4PNtsfz9uiotJyn8bw/77a26jPn8zx79Fld5BsAgAAuOmNWwZKqli/CTRlJWXlSp2zTOP+uVo5hRWVlI9VTgOv0q55lBmhNdqqysJANY38xwq9ueaoV55Z7mZBoEMZeVqw7aRbfX/Yd7YxIfkFkk0AAAA3dYyveDnfcDTL5EiA2h2pTCwzC0o0/pU1kqR1RzPt+uxOP+/zuDyhtjXTr3hpivv2E9XTdCf3aytJSnAyw+Hmtzfqqe/313m/krJyvbb6iOcCbKJINgEAANzUIqri5XLJ/sAfkYB/23Ss+hcipeWGSssN/XnRAUnSqG6tJEnzNh7XN7v9rzhNSIjr6rMD2jf3yjOfrkwgB7Rvrtlje0iqfe/d0rLap/Rm5Nnv1elszem5/GIVlPh3MTKSTQAAADeF1vKSCzQlLyz7ye749VWHre3fXtnd2n7iq4riNOcLS/W3xQdU7ON1jw2RW1hR2CgpNkKPVyZ+VbaeyHGYLuwJhzLyJUn3DO8si6Xu74HCOv4ej5yzj/HOeVvs/u4/2nxc419Zo1EvrLRu8eKPSDYBAAAaoKSOkQvAkwzDUOqcZfp0q3tFfWoWy1my/6xCLRW/MEmKi3ToP/rlVfpoywmN+McKj8TrTecrq+h+eOclurZ/O/3jur52199c6511m5LUp12cJOmO1ORaf/m082TtU5Qf+nS7w7k/L6qefvu3JQet7TvnbXbo6y9INgEAABrgL4sPmB0CgsiJnEJJ0p8XHdCSfWf0+faTSp2zTPd/vM2h72s2o5hv3VpR1OrwuQKVGVJZeUWhm7uGJHs/6BrO5RfX3ckN54tKZZEUExEqSRrWpaV1arAkfbmzcVuS1KZZREVxsP/uOKWycsNuOuySfWes7ZrJpGEY2no8W5J0qvL/pSRN7NPG2v5iZ7oW7T2j1DnL7D7bu02c5/4APkayCQAA0ACfbz9ldggIIlM/2GJt//aL3Xryu4pRsA1Hs+ymWRaXluv11dUje33bOV/DeP/Irta2UaPS6htrPF+45of9ZzX+lTUeKeCTW1Sq2MgwhVROZ7VYLJozpY+eGN/T2qeqAq8nDexQ/XeZVVBx/6UHzmrexjSVlhv67Re7HT6z4lCGUucs0/xtJ/Wr/2xV6pxlmvT6Ouv1/xndXfeN6Gw9fuxLx3vc2ZywkwAAIABJREFUPayzwzl/QbIJAABQD8/XmLIHeNKk19ZqqpNpk5kFrpOn9PPV+zU2ZBrs8exCu+NXV9onm2+sOaIb31pf7/va2lhZsMgTW5N8vv2U8otLHc4PSm5hbf/+68btgenMluPVRXyGdWkpqWKk+bmlh/SVi9HUR+bvlCQ9s8j5TIiYiFBNG1p7Mtk8yn+3WiLZBAAAqIcRXRPMDgEByjAMnTpfpB11rPeradXhzFqv35HqfMrslMotPBbXst9juWHo1ZVHdPhcgb7b07DKtUWl5fpwc/Va07N5DZ9Ou/d0rgpLy1XmZNvLDi2ire0Vh85Zpww3lrPpv/cMt08Q/++7fQ596nr+nyZcYG1f3r2Vy37+vK8vySYAAEA9jUxJsO65CTTUnvTz+tZm65H8BlYdffaHg07Pr54xUpL08Kiu+ujOS3R591ZaeM8Q6/UeibGSpJeWV1Surdo/0pbtnpYHzuY1KL6RNUZbpzspjuOO1DnLdNt7m2rt89IN/aztoc8t14JtJxv0LFtHzzlWt61au+nM+F6JkqQ73q891os6VI/E/m1yH6d9lj483J0QmyySTQAAgHpaceic0rIK6+4I1OLXn+3Q/361x7pmMreoOrErNyr2xiw3DD36ecVUTGfJoCvrZ41SWGj1q37XVjH62+Q+dpVod6fbj6D+/KIO1nZVAppbVD1dtWqf2cbafyav0VusjOnZ2un5IZ1b2h2/vvqIXl15WA994lhIyV1p2Y7JZnS46zTq2z0VhYL2nXGdnN9+SUe1bW7/C6uXbRJlSVry4PBak1p/QLIJAADQQKUemqaH4HQuv2Id5rKD5yRJTyysLg7zyorDGvbccg15drmWHsiQJHVs4dnR9OmjqosExYSHqntiM+vxO+uOqdww7NaDRoY1LHVoGe2YpNpu8+GOmlu5PDPpQrc+dzq3WG+sOaq1R7L0mwU7GzS19qPNjtvN1EwUq8y8opt62Pw9ujLBpgptlcGdW+rjqZfoh4eG6+1bByrOj9dqViHZBAAAaKA0L2wej+Cz/GCGSsvKFWczcvj2umMO/dLPF+mZa3rryQm9nN6nvqOFLWMirO2qKbwfT73Eem7Is8v1q/9srTWmuhiG4bS40Rc70/W7L3a5dY9yw9BNb2+o97Nr+vFghv7wTf0LB+1Oz5Uk3ZHa0e7889f21fxpqdbju4d10i0Xd9D7t19s18/ZVNi2TvY6laQuCTGKjQxTHxdVhP2N/6fLAAAAPnZt/7aav+2UysXIJhrv8x2n9PmOU3psTHctO5jhst8nW0/qt2N6SJJGpCTIMKTRL6+yXm9IJdqauiTEuLzWvXXdI3Y1DX52ubX9xd2D7bb9WLzvrH6zYKf+PsX5esUqX+5M1wmbirlDu7SspXftjjdi+vvUIZ3sjkekVBQL+/SuVJWWlyulVcXfT9WWLJL0+s0D1CwiTE9O6KWU1jFKiIlQVkGJXxf9qQ9GNgEAAOrp0pSKypHstYmGKilzHIV0tT1GlVbNqkciYyPDFBcVpgHtK0bAau6V6a67hjhWqh3VzbEyanioRceyGjeS37Z5lO4eZp+w/VhLcl3l3Rojqr+5olut/dfOvNRuxNHW9pM5Tv/ua1O1zYmrBLFTy2hrolnTwI4VRYDG905Sj8RYtWoWoW4NSNr9FckmAABAPVW9dM/beNzkSOCvhj9fv1HI/5vQS9/cN9Th/LCuFYlQQ7f5mDa0sy7q0Fxf29z7xoHtHPqVlBk6mlmgm9/eYFc0qDYjnq8e1bywbZwk6Z7hXdSvXZxdv9Iayd/aI5n6+5ID1gT6iM109esHtFOnltGqTYjFoo7x0fp/43s6vV6fv/ucwhKtrmNrGWf+88tBeu7a2kdsgwHJJgAAQD31aRtXdyegkb6+d4jCQix669aBuqp3ktM+VUnmeZsEsGrrDXdEhIXotZ8PVGubUdOosFBr+6Ub+mn9rFHW40MZ+bripVXKdLL3ZE3FNpthvnHLQGv7zVsvsuu3KS3b2i43DD30yXZ9uPmECkrsk9AZl6Xod2N6yGIzTbU2k/q21dqZl2rVjJH6+2T7gkLujgRf+fJqt/rV1K11M41Mcb13ZrAg2QQAAKinAZX747lTdRKoaYtNclXTxR2r915sHRup1Y9cqr61FIupmtr5xpqj1nN/clFAyF2RNtt61NxKpMrp83Unm7bCQlwniAt3pVvbtnuGFpSU6XBGvvX4F5fYF+hxR4jFovDQEF3WvbU+vrO6+NEDHzvfCmVLWrZdBV40DskmAABAA1zUobn2n8lz2JIBqE1Wfonu/nCry+sv3dBPyfFRDnsuupJfXFFF9kOb7TlC3Bz5c6XcyZTcjvH2W30cPpfv0Mf6ecNQWh3rO9fPGqVXb+ovSYq32RrldG51EnvVq2t0oweq0Fbp0qq6+NGGY44Jf2m5obs/3KprXlvrsWcGO5JNAACABth8PEeS9OR3++p8sQakiqmbY1+xn5a5bPoIfXZXRTGbC5JiFR4aos+mDdZgFyOKNdWcXhsbGeqip/sSKqfUPjCyi/Xc/GmD7fpE1LLn5jvrjunaN9Zbj/99xyCn/dpUbv8xb+NxlVdOax3Ywfko7vUDHNeRNkT7WvYqnfrBZrtj26m2XztZL4u6BUfNXQAAAC/5ZvdpfbP7tFY/cmmtUwWB11cfsTt+69aBig4PVXLLaLt1kfURWSPpG9/L+drO+mjXPEpf3zvErvqtJH3+q8H6cPNxzdt4XKW1FCSqWVCnu4vp5rbLJrcdz9EjC3Yot6jMad/fXtndzehrN/em/tbtV0rLDeu/2bziUu05nWvXd/+ZPGu7dY2/C7iHkU0AAIAGeO82+yIn2U42rgeqZBWU6PXV1esqk2Ijal2L6a7o8OqRzFsHddDvKvfhbKzWsZEOhXjat4jSjQPbS5KKSp0nhZIUavNLlw61jCS2ax5pbd/94VaXiaYkt4sC1aVt8+p4jtvMSPj1pzsc+uYWVxRdevqa3h55djAi2QQAAGiAC5Ji7Y7P5tavYAqCS0GJfSK18F7PTMu03fvxkctr33/SE6pyvj9+s08fbEhz2mfD0Sxru2qqrDNhoa5TkR8eGm5tV+1z6SljeraWJC09UL3H59YTOXZ9vt97Rvd+WFFEKCEmXGgYkk0AAIAGqDnS8v2+MyZFAn9wwGZK5mXdPLslxhPje2r6qK4evacrLaKqE6/nfzwkwzC0/0yuTuUUOu3/Uh2Fjn5/lfO9MG2T6Ibsc1mbfu0rRpRfWv6T9VzNtZyPf7nb2s4udG9fUTgi2QQAAPCAd9YdMzsEmKTcMPS3xQdUUua6MvErKw9LqtgC5O9T+nj0+T/r21a3pyZ79J6uNIuwL0D0+uojuvXdTdZ1kONrFEAKr2X0UpJGOUm8B7Rv/PTi2oyzWde642SO7pq3WanJ8XZVcW31b8e+ug1FgSAAAAAPyS8u02UvrlSnltH6tLLCKALfkGeXS5I+2nLCZaGfqi1yvrh7sNPr/qLmiL7tOtSs/BKdy69eu7xs+og679c8Klzf3DdUa49kKqugRNf2b6eoGkWP5k/z7L8l22I/U+dtkSRtP3lekrRu5qUaXPn/09o/1vVUYNSOZBMAAKCBnr+ur2Z8Vl1Y5LIXV0qSjmayFUqwsN32pmb1VltVPxMtXIyeBYKa27rYFi+qTatmEZpwYRuH80sfHq4zucXqGB/tkfjcUTOZHt2jtc+eHYiYRgsAANBAI7om6I9XX2B2GDDBmdwi7Uk/b7efZGSo64qpV1fuh1nXtFJ/0LtNbJ19Lk1JaPRzmkWEqUtCTKPv0xh/+dmFpj7f3/n/TzsAAICJJlzYRv+4rq/ZYcCL0rIKNP6V1dYiOM8tPagJc9fq9vc32/U7kVOkcsNx/8mCkjJ9vfu0T2L1hXdvu7jOfUH7eXndZWPVFv/fJ5NgegrJJgAAQCMN79r4URw0Xde+sV7n8kusyeW8jcdd9h1SY72fJH2y5YTXYjPT7LHO9/Ts1DLauh+nP3njloGSpJEprXRFj9Z6+xcX1fEJ1IVkEwAAwAOu6eO45gyBpV8Dq5Iu2H7Kw5E0DVP6t9P6WaMcRgmfndLHbuuSpuqRy1PsjvtXjsaGhlj0159dqD5tqULbWE3/pwAAAMAP/P6qC/TlznSzw4CHvLf+mF5Y9pPm3XGx9VxOYanO5RfX+rlByS0czlUVB+oYH+VwLRB1aum7gj6NccvFHRQWYlFUWKgsrpfbohEY2QQAAPCQxQ8OU0qrGCXEBG7F0WDxwrKfJEm3vrvJem7riRw98/1+p/2rtudoWaPabEFJmbU9745Bng6zSapZ0bWpslgsuumiDvpZv7aa1Let2eEEJJJNAAAAD2keFa4RXROUV1xWd2c0WYaTIj9Vlh7IkCRN7lednIxMSVDH+GhdkBSrwsr9NKssP5hhbbu7FYg/69AiOEZv4R6STQAAAA8qLTdUVFqu4hpJB3zr2R8O6tZ3NzboszUTRkmKjQy1myL761HV6/1+M7qbJCkqLERFNT7rL6N8jTV/WqqS46P0n18Gx+gt3MOaTQAAAA/696aKSqVf7Dyl6wf4X0XOQDBvY5r1/0NhSZmi6jmimO9kZLpXUqwy8kusx3FRYVo381IVlZZb77/1RI71eklZuZ76fr8WBsk63o7x0fps2mCzw0ATw8gmAACAF/x50QGHUS74xnNLD1nbl76wst6ff299miQpMqziVfnpa3prw7Fs/ZSRb9fPYrG4TGRvfGuDXaL5q6Gd6h0H4O9INgEAADzot1d2t7ZfW3XExEiCU2GJ46jkykPn6vxcabmhz7ae0NojmfpgY0Wyee/wzlo/a5TGXpBo17fmcZXBneKt7ePZhXbXJrI1DoIQySYAAIAHTenfztr+ZndwTKFsSjalZTucmzF/R52fm7vysJ5ZdEAPfbLdeu7WQR2t7apRTkl6eFRXp/dYdzRLkpQ6Z5nd+fjocHWM94/tQABPItkEAADwoLCQ6oIwthVL4Rul5a4rydbm7XXHHM6F2vy/fP/26v022zV3XnHVNiG19fmvWMuI4ESyCQAA4GFPjOspSQoJkkqkTUlOYYnT82W1JKElZXWvre2SEFNnn/tHdHF6PiYi8Lc8AZwh2QQAAPCwn1WOaL6x5qjJkQSfP36zT5K09OHhuvmi6mrAn+845fIzmfnOE9SanpzQSy/f0M/ldWcJ6fpZo9y6NxCISDYBAAC8pKFTOtEwtqOaMeGheuTybtbjZ77fr+mfbnf2MR0+l+/0fE3jeydpcOeWLq+PSEmwO55wYZJb9wUCFckmAACAF53JLfL4PcsNo9ZpocHqky0nrW2LxaLQEIs+sFlrufpwphbuTNfe9Fy7z52oUTlWkh6+1HkRoLqsnjHS2v7j1b0adA8gUISZHQAAAEAgyy4sVWJspEfvOWvBTq04dK5BUzSLSstVXFquuKjAew18ZeVhSVKUTaGemlNb//DNXmt7zSOXKjTEoqe+3y9JumtIsto2j9K1NhWF6yssNESfTL1EJ3IcE1gg2DCyCQAA4AXXVSYsh87mefzeKyr3jfzxwFlNnLtGqXOWaefJHP1r9RGHUbuaRv5jhUa/vMrjMTUltvtgRoSFaETXBKf9hj63XBl5xdbjn1/coVGJZpXOCTEa1sX5M4FgQrIJAADgBcMrE5zZC/d47Rm/+XyXTudWJEt3ztuiuauO6Lb3N7n12cz84ro7+ama+2A+d20fl32venWNtd0yJsJrMQHBiGQTAADAC/q3j/PKfZfuP1tnH8OoWM95KCNP5Ub12s7xr6y2tr/cme754JqImkmjxWLRC9f3NSkaIHiRbAIAAHiBN0bJDmfk69H/7qqz3+Bnl2tTWpZufnujPtiQpqyCEt3+3iads9ni44VlP3k8PjNl1bF9SWon11VkAXgHySYAAICX1ZUIuaOwpEw3vr3B5fV7hne2O773w22SKpLKsf9crT2nHddy2o56+rsVP2XUej0sxGJt//DQcIfrcZGBVzAJMBvJJgAAgJeNtZm+6kpWQYkKSsqcXtubnqtv95y2O7d25qXW9gMju+juYZ312Nge9Yrr/o+21at/U9YmrqLir6tiQLZiI8McKvkGUuINNBUkmwAAAF7y/HXV6wSNWpKZp7/fp7H/XK1RL6y065+WVSBJuu39TXryu/12nwmxVI/UtW8eJUn6Wd+2DvduUWOLk6FdqqeTbkrL1qkmukWHYRjKL3aefDvzwMfbJUn3jejsss8Xdw+2+3+y5pHqhP3lG/o1IEoAtSHZBAAA8JLU5Hhr+9+bjrvsN3/bKYdz9364Vde+sV77z7jeyuTR0d0kSZd2ayWpYqrogl+l2vXJLiy1tj+8c5D+cZ19oZynv7dPYpuKV1cd0WUvrtS6I5l19j18Lt/ajolwPR22bfMou5HPUJuptT2TYhsYKQBXSDYBAAC8JCKs+lXruaWHVFruOLpZWlZuf1zZZ/PxHEnSre86bmVyUccWkqSbLuqg9bNGKSYi1HqtapSzpnuGdVZKq2Z2I6KSlBjbNLf7eHPNUUnSg59stztvGIZyi6oT6P1ncnXjW9VrWaPC6vd6+/5tF+v/JvRSeCivxYCn8a8KAADAi26/pKO1/cbqIw7X39uQZnf8/vpjtd5vfK9EvXbzAJfXLRaLVvx6pMMIZojNW9+zU6r3nfzvjqa3BcqmtCy741M5hTqUkad1RzI1+NnluuKlVUqds0zp54u0/0yeXd+4qPoV+rmgTayu6p3U6JgBOCLZBAAA8KIbL2pvbb9fI7GUpH+uOGx3/PKKw1pYyx6Yvxndvc5nRoaFaHiNQjnHsqrXZl7arZXe+cVFdd7HLFWVdKtMen2dbn57o8Mo55L9Z/X7r/fanYsODxWApoFkEwAAwIvaNY/S/GkV6yh/OTjZet4wDC3cma4L28ZJkv4yqbf12h++2Wu3VYck/X3yhWoWEar46HC3n92pZbS1HVZj+mzVcyXp9Pkit+/ZlKRlFtgdv3B9Xxc9AZihzmTzscce07Bhw3TNNddYz+3Zs0c333yzJk2apPvuu0+5ua4XrgMAAAS7dpXrKOeuOqKyyjWZV7y0Sn/4Zq92nTovSRqR0sruM1VrN/u1i9N/7x6sy7q31tKHR9TruTMuS5EkjUxJ0OxxrrdFmfja2nrd11ceHNml1uufbj1hbc+9ub+Gdal72xMAvlNnsnndddfpX//6l9252bNna9asWfriiy80ZswYh+sAAACoZlv1dPRLqyRJeTW29Yh0UdjmzVsvsiar9XVpt1b6/v5heu7avrLUGNmUpOT4ht3XXasPn1NmfnGDP3/nkE5Oz796U39JUpkhJcSEa3yvRF3cMd5pXwDmqTPZTE1NVYsWLezOHT58WKmpFdNBRowYoe+++8470QEAAASY/JIyl9NWv39gmN3xTQPbO+1XH/ExrqfdfnpXqstrjZVfXKbpn+7QuFfW1PuzHVpEqWNlIjzHpphRlT42U4ALSsrUqlnTrKgLBLsGrdns0aOHFi9eLEn65ptvdPLkSY8GBQAAEMjmrjrs9HzN9ZgzLk/xahwWi0W928RqWJeWHr/377/eY22nzlkmw3Dc9sWV49mF1unGo7q10vpZo+yuR4WHyqKKLWAKSsopCgQ0UQ1KNp966inNmzdP1113nfLy8hQRwW+TAAAAavP42Oo1kzW3G/nq3iHW9g0D2lnbvtj78VROkVYfzvT4fZceyLA7dlaJ15mzuRWjvidznI/+Vo10GpI2p2VLkhbvO9PAKAF4U4O+wbp166Y333xTn332mSZOnKjk5OS6PwQAABDEru3fzun5yLAQJcZGWo8fubybr0KSJGUWlPjkOS8s+0lZBSXaeKx6D83colLtPJlj12/yv9Y5/fzUIRXvm5ckO67NPHyuwOEcAPPVb9fbShkZGWrVqpXKy8v1yiuv6Oc//7mn4wIAAAg4L93QTw/V2CuyZoXZiLAQh2mj3nRh2zhrRdzaFJSU6YMNadqYlq0NR7P0xi0D1a9dnNPCQ66M/edqSRVrUR+9sruuqCyW9NldqUqu3KaluKxi+mx0uP2YyAMju+qBkV2d3veq3kluxwDAd+pMNmfOnKl169YpMzNTo0aN0sMPP6z8/HzNmzdPkjR27Fhdf/31Xg8UAADA3w3p7Lg2suZ+mr7Wp22cdp86L8Mwak0c31p7VG+tPWY9nvbvLdZ2fZPjj7ac0IAOza3HG49lKblltN26zi/uHuLso1axkaHKLaqo6HvboI71ej4A36gz2Xz22Wednv/lL3/p8WAAAAAC3WNjuuuZRQckVU8NNVN8dJgMSf+7cI8evLSr2rdwvh1Kfo2tWmpTXpk0jkxJ0MzLu+mWdzeqqLTcrs/shdUFhJ76fr+m9G+nBdtPWc/FRdX+mvro6O76/dd7JUkXtIl1OzYAvuP9VecAAACwst2mw9W0UF8qLKlIAr/be8bleknJfq/Quiw/eE6StOLQOSW3jNbcmwfU2n/6qIq/h1CbkdWQOqbnjr0g0e14AJijQWs2AQAA0DDDuyZIkiJCzZ0+W2VY15Z6z6ZSrKvptFVbkThTVm7YJaN5xaWSpHuGdZYktahjlLLq1ufyiyU5rtd0Jjw0RK/e1N+aLANoehjZBAAA8KHw0BA9NbGXPr0r1exQJElHalRyHfzsch08m+fQLzKs+rWxf/vmdtc+3XpSD368TcezK+717Z7TkqTOCRVFf2yn5j50qeNo7rHMAq04lKGXVxyWJH081b2/m0HJ8RqRkuBWXwC+R7IJAADgY+N6Jaltc+drI33N2ZYsP39no8O5ApsRxOv6t9MHt19sPf7bkgNadzRLU/61XpI0onL0tiopDbFY9OpN/fXC9X0dElVJ+nzHKT0yf6f1OCY8tIF/GgBNCckmAABAEAsNsbg1ylpYUlEgKCEmXON6JapnUqxG92jt0C/9fJHWHanYSzMmojppHJQcr2FdEnRRxxZ6dkofSdLfJ1/o9FmxkSSbQCBgzSYAAECQ61S5x2VtikrL1alltF1iesfgZC3Zf9au3zWvrbW2YyKcv2pe2q2Vy+1SVvx6ZL327gTQdDGyCQAAgDoVlZbbrduUpC4JtSep7uwheuPA9nbHNZ8BwH/xrxkAAAB6YGQXSdKEC5MkScWV+2Jm5Zfo/o+26seDGQ5rKT2xtvJ/ruyulb8e2ej7AGh6LIZhuK5j3Uhnzpz31q0BAADgBalzlrm8FmKR1s60n/46c/4OLT90zml/V1NlnVm094zaNo9U33aOBYQANF2JiXEurzGyCQAAAKsrnBT9qeJsq81fX5aihJhwh/NVRYDcNeaCRBJNIMAwsgkAAACr84WlGv3yKpfXXY1W7judqwc+3qZP70pVi2jH5BNAYKptZJNqtAAAALBqVsu2I4M7xbu81jMpVoseHO6NkAD4KZJNAAAAWIU42XbkN1d008Q+bRTtgYJAAIIHySYAAACcempiL5WWG5pwYRuzQwHgh1izCQAAADtHzuUrNMSijvG176MJAKzZBAAAgNs6J8SYHQKAAMDWJwAAAAAAjyPZBAAAAAB4HMkmAAAAAMDjSDYBAAAAAB5HsgkAAAAA8DiSTQAAAACAx5FsAgAAAAA8jmQTAAAAAOBxJJsAAAAAAI8j2QQAAAAAeBzJJgAAAADA40g2AQAAAAAeR7IJAAAAAPA4kk0AAAAAgMeRbAIAAAAAPI5kEwAAAADgcSSbAAAAAACPI9kEAAAAAHgcySYAAAAAwONINgEAAAAAHkeyCQAAAADwOJJNAAAAAIDHkWwCAAAAADyOZBMAAAAA4HEkmwAAAAAAjyPZBAAAAAB4HMkmAAAAAMDjLIZhGGYHAQAAAAAILIxsAgAAAAA8jmQTAAAAAOBxJJsAAAAAAI8j2YTbTp48qdtvv10TJkzQxIkT9c4770iSsrKyNHXqVI0bN05Tp05Vdna2JMkwDD355JMaO3asJk2apJ07d1rvNX/+fI0bN07jxo3T/Pnzred37NihSZMmaezYsXryySfFkmJ4W1lZmaZMmaJ7771XknTs2DHdeOONGjt2rGbMmKHi4mJJUnFxsWbMmKGxY8fqxhtvVFpamvUec+fO1dixYzV+/HgtX77cen7ZsmUaP368xo4dq9dee823fzAEpZycHE2fPl1XXXWVrr76am3evJnvaPitt99+WxMnTtQ111yjmTNnqqioiO9o+JXHHntMw4YN0zXXXGM954vvZFfPMIUBuCk9Pd3YsWOHYRiGcf78eWPcuHHG/v37jb/85S/G3LlzDcMwjLlz5xp//etfDcMwjKVLlxrTpk0zysvLjc2bNxs33HCDYRiGkZmZaYwePdrIzMw0srKyjNGjRxtZWVmGYRjG9ddfb2zevNkoLy83pk2bZixdutSEPymCyZtvvmnMnDnTuOeeewzDMIzp06cbX375pWEYhvHEE08YH3zwgWEYhvH+++8bTzzxhGEYhvHll18av/71rw3DMIz9+/cbkyZNMoqKioyjR48aV155pVFaWmqUlpYaV155pXH06FGjqKjImDRpkrF//34T/oQIJv/zP/9jfPTRR4ZhGEZRUZGRnZ3NdzT80qlTp4wrrrjCKCgoMAyj4rv5008/5TsafmXdunXGjh07jIkTJ1rP+eI72dUzzMDIJtyWlJSkPn36SJJiY2OVkpKi9PR0LV68WFOmTJEkTZkyRYsWLZIk63mLxaKBAwcqJydHp0+f1ooVKzRixAjFx8erRYsWGjFihJYvX67Tp08rNzdXAwcOlMVi0ZQpU7R48WLT/rwIfKdOndLSpUt1ww03SKr4reKaNWs0fvx4SdK1115r/RlcsmSJrr32WknS+PHjtXr1ahmGocWLF2vixImKiIhQcnKyOnfurG3btmnbtm3q3LmzkpOTFRERoYkTJ/LzDK86f/681q9fb/15joiIUPPmzfnooq9aAAAEZklEQVSOht8qKytTYWGhSktLVVhYqMTERL6j4VdSU1PVokULu3O++E529QwzkGyiQdLS0rR7924NGDBAGRkZSkpKkiQlJiYqIyNDkpSenq62bdtaP9O2bVulp6c7nG/Tpo3T81X9AW95+umn9eijjyokpOKrMDMzU82bN1dYWJgk+5/B9PR0tWvXTpIUFhamuLg4ZWZmuv3zXHUe8Ja0tDQlJCToscce05QpUzR79mzl5+fzHQ2/1KZNG91111264oorNHLkSMXGxqpPnz58R8Pv+eI72dUzzECyiXrLy8vT9OnT9fjjjys2NtbumsVikcViMSkywH0//PCDEhIS1LdvX7NDATyitLRUu3bt0i233KIFCxYoOjraYR0a39HwF9nZ2Vq8eLEWL16s5cuXq6CgwG69JRAIfPGdbPb3Pskm6qWkpETTp0/XpEmTNG7cOElSq1atdPr0aUnS6dOnlZCQIKniNy+nTp2yfvbUqVNq06aNw/n09HSn56v6A96wadMmLVmyRKNHj9bMmTO1Zs0aPfXUU8rJyVFpaakk+5/BNm3a6OTJk5IqXurPnz+vli1buv3zXHUe8Ja2bduqbdu2GjBggCTpqquu0q5du/iOhl9atWqVOnbsqISEBIWHh2vcuHHatGkT39Hwe774Tnb1DDOQbMJthmFo9uzZSklJ0dSpU63nR48erQULFkiSFixYoCuvvNLuvGEY2rJli+Li4pSUlKSRI0dqxYoVys7OVnZ2tlasWKGRI0cqKSlJsbGx2rJliwzDsLsX4GmzZs3SsmXLtGTJEj377LMaOnSo5syZoyFDhujbb7+VVFH9bfTo0ZIqfp6rKsB9++23Gjp0qCwWi0aPHq2FCxequLhYx44d0+HDh9W/f3/169dPhw8f1rFjx1RcXKyFCxda7wV4Q2Jiotq2batDhw5JklavXq1u3brxHQ2/1L59e23dulUFBQUyDEOrV69W9+7d+Y6G3/PFd7KrZ5jBYhjULYd7NmzYoF/84hfq2bOndY3bzJkz1b9/f82YMUMnT55U+/bt9fzzzys+Pl6GYehPf/qTli9frujoaD399NPq16+fJOmTTz7R3LlzJUn33Xefrr/+eknS9u3b9dhjj6mwsFCjRo3SE088wZQveN3atWv15ptvau7cuTp27JgeeeQRZWdnq3fv3vr73/+uiIgIFRUV6dFHH9Xu3bvVokULPffcc0pOTpYkvfLKK/r0008VGhqqxx9/XJdddpkk6ccff9TTTz+tsrIyXX/99br//vvN/GMiCOzevVuzZ89WSUmJkpOT9cwzz6i8vJzvaPilF154QV999ZXCwsLUu3dvPfXUU0pPT+c7Gn5j5syZWrdunTIzM9WqVSs9/PDDGjNmjNe/kzMzM50+wwwkmwAAAAAAj2MaLQAAAADA40g2AQAAAAAeR7IJAAAAAPA4kk0AAAAAgMeRbAIAAAAAPI5kEwAAAADgcSSbAAAAAACPI9kEAAAAAHjc/wdLBWo5B9FnegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa3e0a03240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.74\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressorPred():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "#                      top_n_train=1000, \n",
    "#                      total=1250,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        accuracy = 0\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                predicted_tags = set()\n",
    "                \n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    sigma = 1 / (1 + np.exp(-z)) if z >= 0 else 1 - 1 / (1 + np.exp(z))\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += -y * np.log(np.max([tolerance, sigma])) if y == 1 else \\\n",
    "                                  -(1 - y) * np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma >= 0.9:\n",
    "                            predicted_tags.add(tag)\n",
    "                if n > top_n_train:\n",
    "                    accuracy += len(predicted_tags & tags) / len(predicted_tags | tags)\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "        return accuracy / (total - top_n_train)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e823c1c65d3d4d2390e571565c6d4e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressorPred()\n",
    "acc = model.iterate_file()\n",
    "print(type(acc))\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(\\textbf W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
